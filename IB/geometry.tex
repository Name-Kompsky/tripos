\documentclass[a4paper]{article}

\def\npart{IB}

\def\ntitle{Geometry}
\def\nlecturer{A.\ G.\ Kovalev}

\def\nterm{Lent}
\def\nyear{2018}

\input{header}

\theoremstyle{definition}
\newtheorem*{fact}{Fact}

\DeclareMathOperator{\Isom}{Isom}
\DeclareMathOperator{\mesh}{mesh}
\newcommand*{\inner}{\innerproduct}

\begin{document}

\input{titlepage}

\tableofcontents

\section{Eucldiean Geometry}

\subsection{Isometries}

Let \((\cdot, \cdot)\) be the standard inner product, a.k.a.\ dot product on the Euclidean space \(\R^n\) where for \(x, y \in \R^n\),
\[
  (x, y) = x \cdot y = \sum_{i = 1}^{n}x_iy_i.
\]
This induces the Euclidean norm
\[
  \norm x = \sqrt{(x, x)}.
\]
Also define the Euclidean distance function
\[
  d(x, y) = \norm{x - y}
\]
which makes \(\R^n\) a metric space.

\begin{definition}[Isometry]\index{isometry}
  A map \(f: \R^n \to \R^n\) is an \emph{isometry} of \(\R^n\) if
  \[
    \forall P, Q \in \R^n,\, d(f(P), f(Q)) = d(P, Q).
  \]
\end{definition}

Recall that an \(n \times n\) matrix \(A\) is \emph{orthogonal} if
\[
  A^TA = AA^T = I.
\]
For any square matrix \(A\) we have
\[
  (Ax, Ay) = (Ax)^T(Ay) = x^TA^TAy = (x, A^TAy)
\]
so we find that \(A\) is orthogonal if and only if \((Ax, Ay) = (x, y)\) for all \(x, y \in \R^n\).

Another point of view:
\[
  (x, y) = \frac{1}{2}(\norm{x + y}^2 -  \norm x^2 - \norm y^2)
\]
so \(A\) is orthogonal if and only if \(\norm{Ax} = \norm x\) for all \(x \in \R^n\).

An example of isometry: let \(f(x) = Ax + b\) where \(b \in \R^n\), then
\[
  d(f(x), f(y)) = \norm{A(x - y)}.
\]
So \(f\) is an isometry if and only if \(A\) is orthogonal.

Surprisingly, it turns out all isometries have this form:

\begin{theorem}
  Every isometry \(f: \R^n \to \R^n\) is of the form \(f(x) = Ax + b\) for some orthogonal matrix \(A\) and some vector \(b \in \R^n\).
\end{theorem}

\begin{proof}
  Let \(e_1, \dots, e_n \in \R^n\) be the standard basis of \(\R^n\). Let \(b = f(0)\), \(a_i = f(e_i) - b\) for \(i = 1, \dots, n\). We want to show that \(a_i\)'s form an orthonormal basis. Firstly
  \[
    \norm{a_i} = \norm{f(e_i) - f(0)} = d(f(e_i), f(0)) = d(e_i, 0) = \norm{e_i} = 1
  \]
  so they have unit length. For \(i \neq j\),
  \begin{align*}
    (a_i, a_j) &= -\frac{1}{2}(\norm{a_i - a_j}^2 - \norm{a_i}^2 - \norm{a_j}^2) \\
               &= -\frac{1}{2}(\norm{f(e_i) - f(e_j)}^2 - 2) \\
               &= -\frac{1}{2}(\norm{e_i - e_j}^2 - 2) \\
               &= 0
  \end{align*}
  Thus \(a_i\)'s form an orthonormal basis of \(\R^n\) and it follows that the matrix \(A\) with columns \(a_i, \dots, a_n\) is orthogonal.

  Let \(g(x) = Ax + b\) which is an isometry. We have \(g(x) = f(x)\) for \(x = 0, e_1, \dots, e_n\). In addition,
  \[
    g^{-1}(x) = A^{-1}(x - b) = A^T(x - b)
  \]
  is an isometry so the composition \(h = g^{-1} \compose f\) is an isometry fixing \(0, e_1, \dots, e_n\). It then suffices to show \(h = \id\). Consider \(x = \sum_{i = 1}^n x_ie_i \in \R^n\). Let \(y = h(x) = \sum_{i = 1}^n y_ie_i\). Then
\begin{align*}
  d(x, e_i)^2 &= \norm x^2 + 1 - 2x_i \\
  d(x, 0)^2 &= \norm x^2 \\
  d(y, e_i)^2 &= \norm y^2 + 1 - 2y_i \\
  d(y, 0)^2 &= \norm y^2
\end{align*}
Since \(h\) is an isometry, \(h(0) = 0\), \(h(e_i) = e_i\) and \(h(x) = y\), we have \(\norm x = \norm y\) so \(x_i = y_i\) for all \(i\). Thus \(h(x) = x\) for all \(x \in \R^n\).
\end{proof}

\begin{remark}
  \[
    \Isom(\R^n) = \{\text{all isometries of } \R^n\}
  \]
  is a group by composition. This is also known as the group of rigid motions of \(\R^n\).
\end{remark}

\begin{eg}[Reflections in an affine hyperplane \(H \subset \R^n\)]
  Let
  \[
    H = \{x \in \R^n: u \cdot x = c\}
  \]
  where \(\norm u = 1\) and \(c \in \R\). Observe that \(u\) is perpendicular to \(H\) and so is a normal vector. The reflection in \(H\) is defined to be
  \[
    R_H: x \mapsto x - 2(x \cdot u - c)u.
  \]
  It is an exercise in example sheet to show that this is an isometry. Observe that if \(x \in H\) then \(R_H(x) = x\). If \(a \in H, t \in \R\) then
  \[
    R_H(a + tu) = (a + tu) - 2tu = a - tu.
  \]
  Thus \(R_H\) fixes exactly the points in \(H\).

  Conversely, suppose \(S \in \Isom(\R^n)\) and \(S\) fixes every point in \(H\). Let \(a \in H\) and defind translation by \(a\) as
  \[
    T_a(x) = x + a
  \]
  which is clearly an isometry. Conjugate \(S\) by \(T_a\), we get
  \[
    R = T_{-a}ST_a \in \Isom(\R^n)
  \]
  and \(R\) fixes \(H' = T_{-a}(H)\). We choose to work with \(H'\) since \(0 \in H'\), making it a subspace of \(\R^n\). Explicitly, if \(H = \{x: x\cdot u = c\}\) then \(H' = \{x: x \cdot u = 0\}\). Then for all \(x \in H'\),
  \[
    (Ru, x) = (Ru, Rx) = (u, x) = 0.
  \]
  Thus \(Ru\) is orthogonal to \(H'\), i.e.\ lies in the orthogonal complement of \(H'\) in \(\R^n\). Thus \(Ru = \lambda u\) for some \(\lambda \in R\) such that \(\lambda^2 = 1\). So \(\lambda = \pm 1\).

  Since \(R\) fixes \(0 \in \R^n\), \(R\) is linear by the previous theorem and either \(R = \id\) or \(R\) is given by the matrix
  \[
    \begin{pmatrix}
      -1 & & \\
      & 1 & \\
      & & \ddots \\
      & & & 1
    \end{pmatrix}
  \]
  i.e.\ \(R_{H'}\). If \(R = \id\) then \(S = \id\). If \(R = R_{H'}\) then \(S = T_aR_{H'}T_{-a}\). Check that
  \[
    S: x \mapsto x - a \mapsto (x - a) - 2(x \cdot u - a \cdot u) u \mapsto x - 2(x \cdot u - c)u
  \]
  is a reflection. Thus if \(S \in \Isom(\R^n)\) fixing \(H\) and \(S \neq \id \) then \(R\) is the reflection in \(H\).
\end{eg}

\begin{remark}
  One can show that every isometry of \(\R^n\) is a composition of at most \(n + 1\) reflections (see example sheet 1).
\end{remark}

From the previous theorem, the subgroup
\[
  \{f \in \Isom(\R^n): f(0) = 0\} = \{f(x) = Ax: AA^T = I\}
\]
is naturally isomorphic to \(O(n)\), the \emph{orthogonal group}\index{orthogonal group}.

As for every \(A \in O(n)\), \((\det A)^2 = 1\), we must have \(\det A = \pm 1\). We call \(\{A \in O(n): \det A = 1\}\) the \emph{special orthgonal group}\index{orthogonal group!special}, denoted \(SO(n)\).

\begin{eg}[\(O(2)\)]
  \[
    A =
    \begin{pmatrix}
      a & c \\
      b & d
    \end{pmatrix}
    \in O(2) \Leftrightarrow a^2 + c^2 = 1, b^2 + d^2 = 1, ab + cd = 0
  \]
  Set \(a = \cos \theta, c = \sin \theta\) and \(b = - \sin \varphi, d = \cos \varphi\) for some \(0 \leq \theta, \varphi \leq 2\pi\). Then we deduce
  \[
    \tan \theta = \tan \varphi \in \R \cup \{\infty\}
  \]
  so
  \[
    \theta = \varphi \text{ or } \theta = \varphi \pm \pi.
  \]
  The first case corresponds to
  \[
    A =
    \begin{pmatrix}
      \cos \theta & -\sin \theta \\
      \sin \theta & \cos \theta
    \end{pmatrix}
  \]
  which is the rotation through \(\theta\) about \(0\). As \(\det A = 1\), \(A \in SO(2)\). The second case gives
  \[
    A =
    \begin{pmatrix}
      \cos \theta & \sin \theta \\
      \sin \theta & - \cos \theta
    \end{pmatrix}
  \]
  which we claim is a relfection: it fixes the line \(\ell\) which passes through the origin and forms an angle \(\theta/2\) with the positive \(x\)-axis. \(\det A = -1\) so \(A \notin SO(2)\).
\end{eg}

\begin{remark}[Orientation]\index{orientation}
  For a finite-dimensional vector space, its \emph{orientation} is an equivalence class of bases --- let \(v_1, \dots, v_n\) and \(v_1', \dots, v_n'\) be two bases, and \(A = (A_{ij})\) be the respective change-of-basis from \(\{v_i\}\) to \(\{v_i'\}\). These bases are equivalent, i.e.\ give the \emph{same orientation}, if \(\det A > 0\).
\end{remark}

\begin{definition}
  An isometry \(f(x) = Ax + b\) is said to be \emph{orientation-preserving} if \(\det A = 1\), and \emph{orientation-reversing} if \(\det A = -1\).
\end{definition}

\begin{eg}{\(O(3)\)}
Let's study \(O(3)\) in detail. Consider first the case \(\det A = 1\), then
\[
  \det(A - I) = \det(A^T -I) = \det(A(A^T - I)) = \det(I - A).
\]
Since \(A\) is a \(3 \times 3\) matrix, we must have \(\det (A - I) = 0\) so \(+1\) is an eigenvalue. Thus there exists \(v_1 \in \R^3, \norm{v_1} = 1\) such that \(Av_1 = v_1\). Set \(W = \generation{v_1}^\perp\), a plane. Then for \(w \in W\),
\[
  (Aw, v_1) = (Aw, Av_1) = (w, v_1) = 0
\]
so \(A\) is \(W\)-stable. Thus \(A|_W\) is a \emph{rotation} of the \(2\) dimensional space \(W\). Choose \(v_2, v_3\) to be an orthonormal basis of \(W\), then \(A\) has matrix representation with respect to \(v_1, v_2, v_3\)
\[
  \begin{pmatrix}
    1 & 0 & 0 \\
    0 & \cos \theta & -\sin \theta \\
    0 & \sin \theta & \cos \theta
  \end{pmatrix}
\]

Now suppose \(\det A = -1\). Then \(-A\) in some basis is of the above matrix form. Thus \(A\) is of the form
\[
  \begin{pmatrix}
    -1 & 0 & 0 \\
    0 & \cos \varphi & -\sin \varphi \\
    0 & \sin \varphi & \cos \varphi
  \end{pmatrix}
\]
where \(\varphi = \theta + \pi\). This is a \emph{rotated reflection} (in particular a pure reflection when \(\varphi = 0\)).
\end{eg}

\subsection{Curves in \texorpdfstring{\(\R^n\)}{ℝ\^{}n}}

\begin{definition}[Curve]\index{curve}
  A \emph{curve} \(T\) in \(\R^n\) is a continuous map \(\Gamma: [a, b] \to \R^n\).
\end{definition}

A \emph{dissection} \(\mathcal D\) is a sequence
\[
  a = t_0 < t_1 < \dots, t_N = b \in [a, b].
\]
Set \(P_i = T(t_i)\) and let
\[
  s_{\mathcal D} = \sum_i \norm{P_iP_{i + 1}}.
\]

\begin{definition}[Length]\index{length}
  The \emph{length} of a curve \(\Gamma\) is
  \[
    \ell = \sup_{\mathcal D} s_{\mathcal D}
  \]
  if this supremum exists (i.e.\ finite).
\end{definition}

If \(\mathcal D'\) is a refinement of \(\mathcal D\) (has extra points added), then \(s_{\mathcal D} \leq s_{\mathcal D'}\) by triangle inequality. Let
\[
  \mesh \mathcal D = \max_i(t_i - t_{i - 1}).
\]
Then if \(\ell\) exists, we have
\[
  \ell = \lim_{\mesh \mathcal D \to 0} s_{\mathcal D}.
\]

\begin{note}
  In fact we have
  \[
    \ell = \min\{\tilde \ell: \tilde \ell \geq s_{\mathcal D} \text{ for all } \mathcal D\}.
  \]
\end{note}

\begin{proposition}
  If \(\Gamma\)  is continuously differentiable, then
  \[
    \ell(\Gamma) = \int_a^b \norm{\Gamma'(t)} dt.
  \]
\end{proposition}

\begin{proof}
  Assume \(n = 3\) to avoid excessive notation. Let
  \[
    \Gamma(t) = (f_1(t), f_2(t), f_3(t)).
  \]
  If \(s \neq t \in [a, b]\), applying Mean Value Theorem to each \(f_i\) gives us
  \[
    \frac{f_i(t) - f_i(s)}{t - s} = f'_i(\xi_i)
  \]
  for some \(s < \xi_i < t\). \(f_i'\) are uniformly continuous on \([a, b]\) so for all \(\varepsilon > 0\) there exists \(\delta > 0\) such that
  \[
    |t - s| < \delta \implies |f_i'(\xi_i) - f_i'(\xi)| < \frac{\varepsilon}{3} \, \forall \xi \in (s, t).
  \]
  So for all \(\xi \in (s, t)\),
  \begin{align*}
    \norm*{\frac{\Gamma(s) - \Gamma(t)}{s - t} - \Gamma'(\xi)} &= \norm{(f_1'(\xi_1), f_2'(\xi_2), f_3'(\xi_3)) - (f_1'(\xi), f_2'(\xi), f_3'(\xi))} \\
                                                               &< \frac{\varepsilon}{3} + \frac{\varepsilon}{3} +\frac{\varepsilon}{3} \\
                                                               &= \varepsilon
  \end{align*}
  i.e.
  \[
    \norm{(\Gamma(t) - \Gamma(s)) - (t - s)\Gamma'(\xi)} < \varepsilon(t - s)
  \]
  for all \(\xi \in (s, t)\). Specialise to \(t = t_i, s= t_{i - 1}, \xi = \frac{t_i + t_{i - 1}}{2}\) and sum over \(i\), we get
  \[
    \sum_i \norm*{(\Gamma(t_i) - \Gamma(t_{i - 1})) - (t_i - t_{i - 1}) \Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)} < \sum_i \varepsilon(t_i - t_{i - 1}) = \varepsilon(b - a).
  \]
  Now if \(\mesh \mathcal D < \delta\) then the reverse triangle inequality gives
  \[
    \left|s_{\mathcal D}  - \sum_i (t_i - t_{i - 1}) \norm*{\Gamma'\left(\frac{t_i + t_{i - 1}}{2}\right)}\right| < \varepsilon (b - a).
  \]
  Finally, as \(\norm{\Gamma'(t)}\) is a continuous function of \(t\), it is integrable so the summation converges to \(\int_a^b \norm{\Gamma'(t)} dt\) as \(\mesh \mathcal D \to 0\). Thus
  \[
    \ell(\Gamma) = \lim_{\mesh \mathcal D \to 0} s_{\mathcal D} = \int_a^b \norm{\Gamma'(t)} dt
  \]
  as required.
\end{proof}

\section{Spherical Geometry}

\begin{notation}
  Let \(S^2 \subseteq \R^3\) be the unit sphere with centre \(0\). A \emph{great circle}\index{great circle}, sometimes also called a \emph{(spherical) line}, is \(S^2 \cap \text{a plane through } 0\). For all non-antipodal pair of points \(P, Q \in S^2\), there is a unique line in \(S^2\) passing through \(P\) and \(Q\). It is given by the intersection of \(S^2\) and the plane through \(P, Q, 0\).
\end{notation}

\begin{definition}[Distance on sphere]
  For \(P, Q \in S^2\), the \emph{distance} \(d(P, Q)\) is the length of the shorter of two line segments \(PQ\) along the great circle through \(P, Q\). \(d(P, Q) = \pi\) if \(P\) and \(Q\) are antipodal.
\end{definition}

\begin{note}
  \begin{align*}
    d(P, Q) &= \text{angle between } \V P = OP \text{ and } \V Q = OQ \\
            &= \cos^{-1} (\V P \cdot \V Q)
  \end{align*}
\end{note}

\begin{definition}[Spherical triangle]\index{spherical triangle}
  A \emph{sperical triangle}, \(ABC\) say, is defined like a Euclidean triangle but with \(AB, AC, BC\) line segments on \(S^2\) with lengths \(< \pi\).
\end{definition}

\begin{notation}
  \(\V A = OA\) etc.
\end{notation}

Set
\begin{align*}
  n_1 &= \frac{\V C \times \V B}{\sin a} \\
  n_2 &= \frac{\V A \times \V C}{\sin b} \\
  n_3 &= \frac{\V B \times \V A}{\sin c}
\end{align*}
which are the unit normals to the plane \(OBC\), \(OAC\), \(OAB\) pointing out of the solid \(OABC\). \(\alpha, \beta, \gamma\) are the angles between the planes defining sides of \(ABC\).

\begin{note}
  The angle between \(n_2\) and \(n_3\) is \(\pi + \alpha\) so \(n_2 \cdot n_3 = -\cos \alpha\). Similarly for the other two terms.
\end{note}

\begin{theorem}[Spehrical cosine rule]
  \[
    \sin a \sin b \cos \gamma = \cos c - \cos a \cos b.
  \]
\end{theorem}

\begin{proof}
  We use
  \[
    (\V C \times \V B) \cdot (\V A \times \V C) = (\V A \cdot \V C)(\V B \cdot \V C) - (\V C \cdot \V C)(\V B \cdot \V A)
  \]
  which we derived in IA Vector Calculus. Note that \(|\V C| = 1\) and
  \begin{align*}
    -\cos \gamma &= n_1 \cdot n_2 \\
                 &= \frac{\V C \times \V B}{\sin a} \cdot \frac{\V A \times \V C}{\sin b} \\
                 &= \frac{(\V A \cdot \V C)(\V B \cdot \V C) - (\V B \cdot \V A)}{\sin a \sin b} \\
                 &= \frac{\cos b \cos a - \cos c}{\sin a \sin b}
  \end{align*}
\end{proof}

\begin{corollary}[Spherical Pythagoras Theorem]
  If \(\gamma = \frac{\pi}{2}\) then
  \[
    \cos c = \cos a \cos b.
  \]
\end{corollary}

\begin{theorem}[Spherical sine rule]
  \[
    \frac{\sin a}{\sin \alpha} = \frac{\sin b}{\sin \beta} = \frac{\sin c}{\sin \gamma}.
  \]
\end{theorem}

\begin{proof}
  Use the identity
  \[
    (\V A \times \V C) \times (\V C \times \V B) = (\V C \cdot (\V B \times \V A)) \V C.
  \]

  Note that LHS equals to
  \[
    -(n_1 \times n_2) \sin a \sin b
  \]
  and note that the angle between \(n_1\) and \(n_2\) is \(\pi + \gamma\).

  Consider the plane through \(0\) that is orthogonal to \(\V C\). We find
  \[
    n_1 \times n_2 = \V C \sin \gamma.
  \]
  Thus the coefficient of \(\V C\) is
  \[
    \V C \cdot (\V B \times \V A) = -\sin a \sin b \sin \gamma.
  \]
  By the symmetry cof triple product, it also equals to
  \[
    \V A \cdot (\V C \times \V B) = -\sin b \sin c \sin \alpha.
  \]
  Equating them we get
  \[
    \frac{\sin c}{\sin \gamma} = \frac{\sin a}{\sin \alpha}.
  \]
\end{proof}

\begin{remark}
  Observe that for small \(a, b, c\), piece of \(S^2\) is approximated better and better by piece of \(\R^2\). Formally,
  \begin{align*}
    \sin a &= a + O(a^3) \\
    \cos a &= 1 - \frac{a^2}{2} + O(a^4)
  \end{align*}
  Thus we can obtain Euclidean version of cosine and sine rule by setting \(a, b, c\) small:
  \begin{align*}
    ab\cos \gamma &= (1 - \frac{c^2}{2}) - (1 - \frac{a^2}{2})(1 - \frac{b^2}{2}) + O(\norm{(a, b, c)}^3) \\
    c^2 + 2ab \cos \gamma &= a^2 + b^2 + O(\norm{(a, b, c)}^3)
  \end{align*}
\end{remark}

Now we discuss the metric property of spherical geometry. If \(\gamma = \pi\) then \(\V C\) lines in the line segment \(AB\) so \(c = a + b\). Otherwise, from Spherical cosine rule,
\[
  \cos c > \cos a \cos b - \sin a \sin b = \cos(a + b).
\]
As \(\cos\) is decresasing on \([0, \pi]\) and \(0 < c < \pi\), \(0 < a + b < 2\pi\), we have
\[
  c < a + b.
\]
This gives us

\begin{corollary}[Spherical triangle inequality]
  \[
    d(P, Q) + d(Q, R) \geq d(P, R)
  \]
  with equality if \(Q\) is in line segment \(PR\) of shorter length.
\end{corollary}
Thus we have shown that \((S^2, d)\) is a metric space.

\begin{proposition}
  Given a curve \(\Gamma\) on \(S^2 \subseteq \R^3\) from \(P\) to \(Q\) with length \(\ell\), we have
  \[
    \ell \geq d(P, Q).
  \]
  Moreover, if \(\ell = d(P, Q)\), then the image of \(\Gamma\)is a spherical line segment.
\end{proposition}

\begin{proof}
  Let \(\Gamma: [0, 1] \to S^2\) with length \(\ell\).For any dissection \(\mathcal D\) of \([0, 1]\) with
  \[
    0 = t_1 < t_1 < \dots < t_N = 1
  \]
  and \(P_i = \Gamma(t_i)\). Define two sums
  \[
    \tilde s_{\mathcal D} = \sum_{i = 1}^N d(P_{i -1}, P_i) > s_{\mathcal D} = \sum_{i = 1}^N |P_{i - 1}P|
  \]
  because the arc is longer than a sector, i.e.\ \(2\theta < 2 \sin \theta\).

  Suppose \(\ell < d(P, Q)\), we can deduce that there exists \(\varepsilon > 0\) such that \((1 + \varepsilon)\ell < d(P, Q)\). As \(\lim_{\theta \to 0} \frac{\sin \theta}{\theta} = 1\),
  \[
    2\theta \leq (1 + \varepsilon) 2\sin \theta
  \]
  for each small \(\theta > 0\).

  \(\Gamma\) is uniformly continuous on \([0, 1]\) so we can choose a refined \(\mathcal D\) such that
  \[
    d(P_{i - 1}, P_i) \leq (1 + \varepsilon)|P_{i - 1}P_i|
  \]
  for all \(i\). Therefore
  \[
    \tilde s_{\mathcal D} \leq (1 + \varepsilon)s_D \leq (1 + \varepsilon)\sup_{\mathcal D} s_{\mathcal D} = (1 + \varepsilon) \ell < d(P, Q).
  \]
  But \(\tilde s_{\mathcal D} \geq d(P, Q)\) by repeated use of spherical triangle inequality. Absurd.

  Suppose instead \(\ell = d(P, Q)\) for some \(\Gamma: [0, 1] \to S^2\). Then for all \(t \in [0, 1]\),
  \begin{align*}
    d(P, Q) &= \ell \\
            &= \operatorname{length} \Gamma|_{[0, t]} + \operatorname{length} \Gamma|_{[t, 1]} \\
            &\geq d(P, \Gamma(t)) + d(\Gamma(t), Q) \\
            &\geq d(P, Q) 
  \end{align*}
  Thus we have equality throughout. By spherical triangle equality the image of \(\Gamma\) is the shorter line segment from \(P\) to \(Q\).
\end{proof}

\begin{remark}
  If \(\Gamma\) is the shortest path between \(P\) and \(Q\) then \(\Gamma\) is a spherical line segment. Furthermore, from argument of the above proposition
  \[
    \operatorname{length} \Gamma|_{[0, t]} = d(P, \Gamma(t))
  \]
  so the parameterisation of \(\Gamma\) is \emph{monotonic}. In further courses in geometry such as IID Differential Geometry, such \(\Gamma\)'s are sometimes called \emph{minimising geodesics}. See example sheet 1 for a similar but easier discussion of geodesics in Euclidean space.
\end{remark}

\subsection{Area of spherical triangles}

\begin{proposition}[Gauss-Bonnet for \(S^2\)]
  If \(\Delta\) is a spherical triangle with angles \(\alpha, \beta, \gamma\), then
  \[
    \operatorname{area} \Delta = (\alpha + \beta + \gamma) - \pi.
  \]
\end{proposition}

\begin{proof}
  We assume the area of \(S^2\) is \(4\pi\) and the additivity of areas.

  A \emph{double line} with angle \(0 < \alpha < \pi\) is two antipodal regions on \(S^2\) cut out by planes through antipodal \(A, A' \in S^2\) where \(\alpha\) is the angle between planes. The area of such double line is \(4\alpha\). Then a triangle \(\Delta = ABC\) is the intersection of 3 single lines. The \(\Delta\) and its antipodal \(\Delta'\) lie in each of the three double lines with angles \(\alpha, \beta, \gamma\). Any other point \(P \in S^2 \setminus (\Delta \cup \Delta')\) is in only one double line. Thus
  \[
    4(\alpha + \gamma + \gamma) = 4\pi + 2 \cdot (\operatorname{area}\Delta + \operatorname{area}\Delta').
  \]
  The result thus follows.
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item spherical triangles have \(\alpha + \beta + \gamma > \pi\). As the area of a triangle tends to \(0\), \(\alpha + \beta + \gamma \to \pi\). Thus Euclidean space is an approximation of sphere..
  \item If \(M\) is a convex \(n\)-gon in \(S^2\) where \(n \geq 3\), i.e.\ for all \(P, Q \in M\), the shorter line segment \(PQ\) is in \(M\). Let the interior angles be \(\alpha_1, \dots, \alpha_n\). Then
    \[
      \operatorname M = \sum_{i = 1}^n \alpha_i - (n - 2)\pi
    \]
    by cutting \(M\) into triangles.
  \end{enumerate}
\end{remark}

\subsection{Möbius geometry}

Consider \(\C_\infty = \C \cup \{\infty\}\).

\begin{definition}[Stereographic projection]\index{stereographic projection}
  The \emph{stereographic projection} is a map \(\pi: S^2 \to C_\infty\) where the north pole is mapped to \(\infty\) and other point is mapped to the intersection of the line through \(P\) and the north pole and the complex plane.
\end{definition}

We will use \(\zeta = x + iy\) to denote a point in \(\C_\infty\). From similar triangles we get
\[
  \pi(x, y, z) = \frac{x + iz}{1 - z}.
\]

\begin{lemma}
  If \(\pi': S^2 \to \C_\infty\) is the stereographic projection from the soth pole \((0, 0, -1)\) then
  \[
    \pi'(P) = \frac{1}{\conj{\pi(P)}}
  \]
  for all \(P \in S^2\).
\end{lemma}

\begin{proof}
  Easy once we write down the coordinates. Suppose \(P = (x, y, z)\). Then
  \begin{align*}
    \pi(P) &= \frac{x + iy}{z} \\
    \pi'(P) &= \frac{x + iy}{1 + z}
  \end{align*}
  and so
  \[
    \conj{\pi(P)} \cdot \pi'(P) = \frac{x^2 + y^2}{1 - z^2} = 1
  \]
  as \(S^2 = \{x^2 + y^2 + z^2 = 1\}\).
\end{proof}

\begin{note}
  \(\pi' \compose \pi^{-1}: \C_\infty \to \C_\infty\) takes \(\zeta \to \frac{1}{\conj \zeta}\), the \emph{inversion} in the circle \(|\zeta| = 1\).
\end{note}

Antipodal points

If \(P = (x, y, z) \in S^2\), then \(\pi(P) = \frac{x + iy}{1 - z} \in \C_\infty\), \(\pi(-P) = \frac{-x - iy}{1 + z}\) so
\[
  \pi(P) \cdot \conj{\pi(-P)} = -\frac{x^2 + y^2}{1 - z^2} = 1
\]
so \(\pi(-P) = -\frac{1}{\conj \zeta}\) where \(\zeta = \frac{x + iy}{1 - z}\).

\subsubsection{Möbius Transformations}

Möbius transformations act on \(\C_\infty\) and form a group \(G\). Given any matrix with complex entries \(A = \begin{psmallmatrix} a & b \\ c & d \end{psmallmatrix}\), define
\begin{align*}
  \C_\infty &\to \C_\infty \\
  \zeta &\mapsto \frac{a\zeta + b}{c\zeta + d}
\end{align*}
For all \(\lambda \in \C^* = \C \setminus \{0\}\), \(\lambda A\) defines the same Möbius transformation. The converse is also true: if \(A_1, A_2\) define the same Möbius transformation then there exists \(\lambda\) such that \(A_1 = \lambda A_2\). Therefore from group theory we know
\[
  G \cong \PGL(2, \C) = \GL(2, \C)/\C^*.
\]
Thus it suffices to assume \(\det A = 1\). But this does not eliminate all ambiguities --- if \(1 = \det(\lambda \tilde A) = \lambda^2 \det \tilde A = \lambda^2\) then \(\lambda = \pm 1\). Thus
\[
  G \cong \PSL(2, \C) = \SL(2, \C)/\{\pm 1\}.
\]

On \(S^2\) we have rotations \(\SO(3)\) acting as isometries (see example sheet). Which Möbius transformations do they correspond to?

\begin{theorem}
  Via the stereographic projection, every rotation of \(S^2\) induces a Möbius transformation defiend by a matrix in \(\SU(2) \leq \SL(2, \C)\).
\end{theorem}

\begin{proof}
  Denote by \(r(z, \theta)\) the rotation about the \(z\)-axis through \(\theta\). Then it corresponds to the Möbius map \(\zeta \mapsto e^{i\theta} \theta\) with a matrix
  \[
    \begin{pmatrix}
      e^{i\theta/2} & 0 \\
      0 & e^{-i\theta/2}
    \end{pmatrix}
    \in \SU(2).
  \]

  Next, the rotation \(r(y, \frac{\pi}{2})\) has matrix
  \[
    \begin{pmatrix}
      0 & 0 & 1 \\
      0 & 1 & 0 \\
      -1 & 0 & 0
    \end{pmatrix}
  \]
  correspond to \(\zeta = \frac{x + iy}{1 - z} \mapsto \zeta' = \frac{z + iy}{1 + x}\) since by drawing a diagram we know
  \begin{align*}
    -1 &\mapsto \infty \\
    1 &\mapsto 0 \\
    i &\mapsto i
  \end{align*}
  The corresponding unique Möbius map is then \(\zeta' = \frac{\zeta - 1}{\zeta + 1}\). We check that
  \begin{align*}
    \frac{\zeta - 1}{\zeta + 1}
    &= \frac{x + iy - 1 + z}{x + iy +1 - z} \\
    &= \frac{x - 1 + z + iy}{x + 1 - (z - iy)} \\
    &= \frac{(z + iy)(x - 1 + z + iy)}{(x + 1)(z + iy) + (x^2 - 1)} \\
    &= \frac{(z + iy)(x - 1 + z + iy)}{(x + 1)(z + iy + x -1)} \\
    &= \zeta'
  \end{align*}
  does give the rotation we want.

  We claim that \(\SO(3)\) is generated by \(r(y, \frac{\pi}{2})\) and \(r(z, \theta)\). Observe that
  \[
    r(x, \varphi) = r(y, \frac{\pi}{2}) r(z, \varphi) r(y, -\frac{\pi}{2})
  \]
  which is a conjugation. To check this, note that the \((1, 0, 0)\) is an eigenvector and the map is orientation-preserving (and some more geometric arguments). Also for all \(x \in S^2 \subseteq \R^3\), there exists \(\varphi, \psi\) such that \(g =r(z, \psi) r(x, \varphi)\) which maps \(v\) to \((1, 0, 0)\): choose \(r(x, \varphi)\) rotating \(v\) to the \((x, y)\)-plane. Then \(r(v, \theta) = g^{-1} r(x, \theta) g\) and the claim follows.

  Thus via projection, any rotation of \(S^2\) corresponds to a finite product of Möbius transformations with matrices in \(\SU(2)\).
\end{proof}

The theorem gives a group homomorphism
\[
  \SO(3) \to \PSU(2) \cong \SU(2)/\{\pm I\}
\]
which is in fact surjective, so an isomrphism.

\begin{theorem}
  The group \(\SO(3)\) of rotations of \(S^2\) correponds precisely to the subgroup \(\PSU(2) \cong \SU(2)/\{\pm I\}\) of Möbius transformations acting on \(\C_\infty\).
\end{theorem}

\begin{proof}
  Let \(g \in \PSU(2) \leq G, g(z) = \frac{az - b}{\conj b z + \conj a}\). Suppose \(g(0) = 0\), so \(b = 0\), \(a \conj a = 1\) so let \(a = e^{i\theta/2}\) where \(\theta \in \R\). Then \(g\) corresponds to \(r(z, \theta)\). In general, \(g(0) = w \in C_\infty\). Let \(Q \in S^2\), \(\pi(Q) = w\). Choose \(A \in \SO(3)\) with \(A(Q) = (0, 0, -1)\). Let \(\alpha \in \PSU(2)\) be the correponding Möbius map in \(\PSU(2)\). Thus \(\alpha(w) = 0\) and \(\alpha \compose g(0) = 0\). So \(\alpha \compose g\) correponds to an element \(B\) in \(\PSU(2)\), and thus \(g\) corresponds to \(A^{-1}B\).
\end{proof}

\begin{remark}
  THa mep
  \[
    \SU(2)/\{\pm I\} \cong \SO(3)
  \]
  is a double cover.
\end{remark}

\section{Triangulations and the Euler number}

First introduce one more ``geometry'': the locally Euclidean torus.

\begin{definition}[Torus]\index{torus}
  The \emph{torus} \(T\) is the set \(\R^2/\Z^2\)of equivalence classes of \((x, y) \in \R^2\) with equivalence relation
  \[
    (x_1, y_1) \sim (x_2, y_2) \Leftrightarrow x_1 - x_2, y_1, y_2 \in \Z.
  \]
\end{definition}

Thus a point in \(T\) is a coset \((x, y) + \Z^2\) of the subgroup \(\Z^2\) of \((\R^2, +)\).

For a closed square \(Q \subseteq \R^2\) with side length \(1\), \(T\) is obtained by identifying the opposite sides.

Define the distance \(d\), for \(P_1, P_2 \in T\)
\[
  d(P_1, P_2) = \min \{|v_1 - v_2|: v_1, v_2 \in \R^2, v_i + \Z^2 = P_i\}.
\]
It is easy to check \((T, d)\) is a metric space.

Let \(Q^0\) be the interior of \(Q\). The natural map
\begin{align*}
  f: Q^0 &\to T \\
  v &\mapsto v + \Z^2
\end{align*}
is a bijection onto an open set \(U = f(Q^0) \subseteq T\). Moreover \(f: Q^0 \to U\) is a homeomorphism. Let \(P \in Q\). \(f\) restricted to small open disc about \(P\) is an \emph{isometry} onto the image. Such \(d\) (on \(T\)) is said to correspond to a \emph{locally Euclidean metric} on \(T\).

\(T\) maybe embedded in \(\R^3\) but the distance function we get by considering curves on \(T \subseteq \R^3\) is \emph{not} the same as the locally Euclidean distance.

\begin{definition}[Topological triangle]\index{topological triangle}
  A \emph{topological triangle} on \(X = S^2\) or \(T\) (or in general, any metric space \(X\)) is the image \(R \subseteq X\) of a closed Euclidean triangle \(\triangle \subseteq \R^2\) under a homeomorphism \(\triangle \to R\).
\end{definition}

For example, any spherical triangle is a topological triangle, by using radial projection from \(0\) to an affine plane in \(\R^2\).

\begin{definition}[Topological triangulation]\index{topological triangulation}
  A \emph{(topological) triangulation} \(\tau\) of \(X\) is a finite collection of topologtical triangles which cover \(X\) and satisfy
  \begin{enumerate}
  \item every two topological triangles of \(\tau\) are either disjoint, or meet in exactly one edge, or meet in exactly one vertex.
  \item each edge belongs to exactly two triangles.
  \end{enumerate}
\end{definition}

\begin{definition}[Euler number]\index{Euler number}
  The \emph{Euler number} \(e = e(X, \tau)\) is
  \[
    e = F - E + V
  \]
  where \(F = \# \text{faces in } \tau\), \(E = \#\text{edges in } \tau\) and \(V = \# \text{vertices in } \tau\).
\end{definition}

\begin{fact}[From algebraic topology]
  \(e\) is independent of the choice of \(\tau\), i.e.\ \(e = e(X)\).
\end{fact}

\begin{eg}
  (See pictures.)

  In both examples we use \emph{geodesic triangles}, i.e.\ used spherical triangles on \(S^2\) and Euclidean triangles on \(Q^0\).
\end{eg}

\begin{proposition}
  Each geodesic triangulation of \(S^2\), repsectively \(T\), has \(e = 2\), respectively \(0\).
\end{proposition}

\begin{remark}
  The results also hold without the geodesic assumption but we will not prove it in this course.
\end{remark}

\begin{proof}
  Denote the faces \(\triangle_1, \dots, \triangle_F\) and \(\tau_i = \alpha_i + \beta_i + \gamma_i\), \(i = 1, \dots, F\) the interior angles. Then \(\sum_{i = 1}^F \tau_i = 2\pi V\). Also \(3F = 2E\) so \(F = 2E - 2F\).
  \begin{itemize}
  \item \(S^2\): Gauss-Bonnet says \(\operatorname{area} \triangle_i = \tau_i - \pi\) so
    \begin{align*}
      4\pi
      &= \sum_{i = 1}^F \operatorname{area} \triangle_i \\
      &= \sum_{i = 1}^F (\tau_i - \pi) \\
      &= 2\pi V - \pi F \\
      &= 2\pi V - 2\pi E + 2\pi F \\
      &= 2\pi V
    \end{align*}
    so \(e = 2\).
  \item \(T\): \(\tau_i = \pi\) for all \(i\) so
    \begin{align*}
      2\pi V &= \sum_{i = 1}^F \tau_i = \pi F \\
      2V &= F = 2 E - 2F
    \end{align*}
    thus \(e = 0\).
  \end{itemize}
\end{proof}

\begin{remark}
  We can use topological polygonal decomposition of \(X\) and the proposition above still holds. The Euler's formula for \(S^2\) is
  \[
    V - E + F = 2.
  \]
\end{remark}

\section{Hyperbolic geometry}

There are three ``classical'' types of ``geometries'' and we have seen two of them: Euclidean and spherical. The third type is hyperbolic geometry. We shall require the concept of \emph{Riemannian metric} on an open \(U \subseteq \R^2\).


\subsection{Revision of differentiability}

It would be convenient to recall from IA Analysis I and IB Analysis I facts about the derivatives and make precise sense of the \emph{differentials}.

Let \(U \subseteq \R^n\) be an open set, \(f = (f_1, \dots, f_m): U \to \R^m\). \(f\) is smooth, i.e.\ \(C^\infty\), if each \(f_i\) has continuous partial derivatives of every order. In particular, \(C^\infty\) implies the existence of continuous derivatives of 1st order so it is differentiable.

The derivatives of \(f\) at \(a \in U\) is a linear map \(df_a: \R^n \to \R^m\) such that
\[
  \lim_{h \to 0} \frac{\norm{f(a + h) - f(a) - df_a \cdot h}}{\norm h} = 0.
\]
If \(m = 1\), \(df_a\) is determined by
\[
  \left( \frac{\p f}{\p x_1}(a), \dots, \frac{\p f}{\p x_n}(a) \right)
\]
via
\[
  df_a: (h_1, \dots, h_n) \mapsto \sum_{i = 1}^n \frac{\p f}{\p x_i}(a) h_ii.
\]

For general \(m\), we may use the \emph{Jacobian matrix}
\[
  J(f)_a = \left( \frac{\p f_i}{\p x_j}(a) \right)
\]
and use matrix multiplication
\[
  h \mapsto J(f)_ah.
\]

\begin{eg}
  Consider a holomorphic, i.e.\ analytic function function of complex variable \(f: U \to \C\) where \(U \subseteq \C\) is open, with derivative \(f'(z)\) such that
  \[
    \lim_{w \to 0} \frac{|f(z + w) - f(z) - f'(z)w|}{|w|} = 0.
  \]
  Suppose \(f'(z) = a + ib\) and \(w = h_1 + ih_2\), then
  \[
    f'(z)w = (ah_1 - bh_2) + i(ah_2 + bh_1)
  \]
  Now identify \(\C \cong \R^2\), \(f: U \to \R^2\) has derivative \(df_z: \R^2 \to \R^2\) given by
  \[
    \begin{pmatrix}
      a & -b \\
      b & a
    \end{pmatrix}
  \]
\end{eg}

Chain rule: let \(U \subseteq \R^n, V \subseteq \R^p\) both open, \(f: U \to \R^m, g: V \to U\) both smooth. THen \(f \compose: V \to \R^m\) has for all \(p \in V\),
\[
  d(f \compose g)_p = (df)_{g(p)} \compose (dg)_p
\]
or in terms or Jacobians,
\[
  J(f \compose g)_p = J(f)_{g(p)} \cdot J(g)_p
\]
where \(\cdot\) denotes matrix multiplication.

\subsection{Riemannian metrics on open sets in \texorpdfstring{\(\R^2\)}{ℝ\^{}2}}

Use the coordinates \((u, v) \in \R^2\). Let \(V \subseteq \R^2\) be open.

\begin{definition}[Riemannian metric]\index{Riemannian metric}
  A \emph{Riemannian meric} is define by giving \(C^\infty\) functions \(E, F, G: V \to \R\) such that
  \[
    \begin{pmatrix}
      E(p) & F(p) \\
      F(p) & G(p)
    \end{pmatrix}
  \]
  is a positive-definite matrix for all \(p \in V\).
\end{definition}

Hence a Riemannian metric defines an inner product \(\inner{\cdot, \cdot}_p\) on \(\R^2\).

\begin{remark}
  There are two ways to view \(\R^2\): one way is the standard vector space \(\R^2\), which has a distinguished zero vector. The other is the affine space \(\A^2\) (space of points) with operation
  \[
    \text{point } + \text{ vector } = \text{ point}.
  \]
  So the inner product could be thought of an operation on the affine space, with \(p\) identified as the zero.
\end{remark}

Let \(e_1, e_2\) be the standard basis of \(\R^2\). Then given the inner product defined above,
\begin{align*}
  \inner{e_1, e_1}_p &= E(p) \\
  \inner{e_1, e_2}_p &= F(p) \\
  \inner{e_2, e_2}_p &= G(p)
\end{align*}

\begin{notation}
  Use \(E du^2 + 2F dudv + G dv^2\) to denote a family of inner products.

  For pedagogical purpose it might be helpful to explain the origin of the notation \(du, db\). Let \(u, v: V \to \R\) be the components of the coordinates, which are \(C^\infty\). Since they are linear maps, their derivatives are just themselves, i.e.\ for all \(p \in V\)
  \begin{align*}
    (du)_p: \R^2 &\to \R \\
    (h_1, h_2) &\mapsto h_1 \\
    (dv)_p: \R^2 &\to \R \\
    (h_1, h_2) &\mapsto h_2
  \end{align*}
  Since the derivatives do not depend on \(p\), we write \(du, dv\) for brevity, which are elements of the dual space \((\R^2)^*\). Furthermore, \(du, dv\) form the \emph{dual} basis to standard basis \(e_1, e_2\) of \(\R^2\). Then \(du^2, dudv, dv^2\) are symmetric bilinear forms on \(\R^2\), with
  \begin{align*}
    du^2(h, k) &= du(h) du(k) \\
    dudv(h, k) &= \frac{1}{2}(du(h)dv(k) + du(k)dv(k)) \\
    dv^2(h, k) &= \dots
  \end{align*}
  with matrices given by ...

  and so \(Edu^2 + 2Fdudv + Gdv^2\) is indeed the bilinear form \(\begin{psmallmatrix} E & F \\ F & G \end{psmallmatrix}\).
\end{notation}

\begin{definition}[Length]\index{length}
  The \emph{length with repsect to a Riemannian metric} of smooth curve \(\gamma = (\gamma_1, \gamma_2): [0, 1] \to V \subseteq \R^2\) is
  \[
    \int_0^1 \inner{\dot \gamma, \dot \gamma}_{\gamma(t)}dt = \int_0^1 (E \dot \gamma_1^2 + 2F \dot \gamma_1 \dot \gamma_2 + G \dot \gamma_2^2)^{1/2} dt.
  \]
\end{definition}

Note that this is compatible with the definition of length in Euclidean metric, with \(E = G = 1, F = 0\).

\begin{definition}
  The \emph{area with respect to a Riemannian metric} of a region \(W \subseteq V\) is defined as
  \[
    \int_W (EG - F^2)^{1/2} dudb
  \]
  whenever the integral exists.
\end{definition}

Note that \(EG - F^2 = \det \begin{psmallmatrix} E & F \\ F & G \end{psmallmatrix}\), the Gram determinant.

\begin{eg}
  Let \(V = \R^2\) with Riemannian metric
  \[
    \frac{4 (du^2 + dv^2)}{(1 + u^2 + v^2)^2}.
  \]
  Recall the stereographic projection
  \begin{align*}
    \pi: S^2 \setminus \{N\} &\to \R^2 \\
    (x, y, z) &\mapsto (u, v)
  \end{align*}
  For all \(P \neq N \in S^2\) have \(\pi(P) \in \R^2\) then the Riemannian metric above give \(\inner{\dot, \dot}_{\pi(p)}\).

  The \emph{tangent plane} to \(S^2\) at \(P\) is
  \[
    \{x \in \R^3: x \cdot OP = 0\}.
  \]
  Then \((d\pi^{-1})_{\pi(p)}\) identifies \(\inner{\cdot, \cdot}_{\pi(p)}\) with restriction of standard inner product on \(R^2\) to the tangent plane.
\end{eg}






\printindex

\iffalse
Other courses that might be useful: topology, part of analysis II (differentiability in R^n and inverse function theorem)

Leads to: IID Differential Geometry

Reading List

P.\ Wilson, Curverd Spaces, CUP 2008
From classical geometries to elementary differential geometry
\fi


\end{document}
