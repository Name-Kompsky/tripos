\documentclass[a4paper]{article}

\def\npart{III}

\def\ntitle{Differential Geometry}
\def\nlecturer{A.\ Kovalev}

\def\nterm{Michaelmas}
\def\nyear{2018}

\input{header}

\DeclareMathOperator{\Gr}{Gr} % Grassmannian
\DeclareMathOperator{\Lie}{Lie} % Lie functor
\DeclareMathOperator{\supp}{supp} % support
\newcommand{\w}{\wedge}

\begin{document}

\input{titlepage}

\tableofcontents

\section{Manifolds}

We want to generalise curves and surfaces in \(\R^2\). A curve is a map \(\gamma: \R \supseteq I \to \R^2\) or \(\R^3\) that satisfies certain properties we'll find out in a minute. Clearly continuity is necessary but not sufficent, as evidenced by the famous Peano space-filling curve. Smoothness is not quite enough either, as \(t \mapsto (t^2, t^3)\) has a cusp at the origin. The correct requirement will be that \(\gamma\) has regular parameterisation, i.e.\ \(|\dot \gamma(t)| \neq 0\) for all \(t\).

Similarly, a surface should be defined as as a map \(r: \R^2 \supseteq D \to \R^3\) with a regular parameterisation, i.e.\ \(r \in C^\infty(D)\) and \(\left| \frac{\p r}{\p u} \times \frac{\p r}{\p v} \right| \neq 0\) for all \((u, v) \in D\).

We may follow this route and generalise to (hyper)surfaces in \(\R^n\), which will be a generalisation of classical differential geometry of curves and surfaces in \(\R^3\). The good thing is that we can readily apply calculus and it is easy to construct these objects. However, it does suffer from the prolblem of different parameterisations give rise to different geometric objects, as well as some surface requiring more than one parameterisation. Although these can be bypassed more or less, the more serious drawback is the extra technical complexity determined by the higher dimension of the ambient space.

A better concept is \emph{smooth manifolds}. We first begin with a review of topological structure, which every manifold possesses.

\begin{definition}[topological space]
  A \emph{topological space} \(M\) is a choice of class of the \emph{open sets} such that
  \begin{enumerate}
  \item \(\emptyset\) and \(M\) are open,
  \item if \(U\) and \(U'\) are open then so is \(U \cap U'\),
  \item for anly collection of open sets, the union is open.
  \end{enumerate}
\end{definition}

In this course, we always require a topological space to be Hausdorff and second countable.

\begin{definition}[local coordinate chart]\index{chart}
  A \emph{local coordinate chart} on a topological space \(M\) is a homeomorphism \(\varphi: U \to V\) where \(U \subseteq M\) and \(V \subseteq \R^d\) are open. \(U\) is a \emph{coordinate neighbourhood}.
\end{definition}

\begin{definition}[\(C^\infty\)-differentiable structure]\index{differentiable structure}\index{atlas}
  A \emph{\(C^\infty\)-differentiable structure} on a topological space \(M\) is a collection of charts \(\{\varphi_\alpha: U_\alpha \to V_\alpha\}\) where \(V_\alpha \subseteq \R^d\) for all \(\alpha\) such that
    \begin{enumerate}
    \item \(\{U_\alpha\}\) covers \(M\), i.e.\ \(M = \bigcup U_\alpha\),
    \item compatibility condition: for all \(\alpha, \beta\), \(\varphi_\beta \compose \beta_\alpha^{-1}\) is \(C^\infty\) wherever defined, i.e.\ on \(\varphi_\alpha(U_\alpha \cap U_\beta)\),
    \item maximality: if \(\varphi\) is compatible with all the \(\varphi_\alpha\)'s then \(\varphi\) is in the collection.
    \end{enumerate}
    
    The collection of charts is called an \emph{atlas}.
\end{definition}

Note that 2 implies that \(\varphi_\beta \compose \varphi_\alpha^{-1}\) is a diffeomorphism.

\begin{definition}[manifold]\index{manifold}
  A \emph{manifold} is a Hausdorff, second countable topological space with a \(C^\infty\)-differentiable structure.
\end{definition}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item In practice, we almost never specify the topological structure. Instead, we can induce a topology from a \(C^\infty\) structure by declaring \(D \subseteq M\) open if and only if for all \((\varphi_\alpha, U_\alpha)\), \(\varphi_\alpha(U_\alpha \cap D)\) is open in \(\R^d\).
  \item We may replace \(C^\infty\) by \(C^k\) for \(k > 0\) finite. If we set \(k = 0\), the objects become topological manifolds. On the other hand, use \(\C^n\) and holomorphic maps we get complex manifolds.
  \item Requirement of being Hausdorff and second countable are for rather technical reasons. In some cases we may drop Hausdorffness requirement, and such examples do arise naturally. However in that case we lose uniqueness of limits. Similarly non-second countable space, such as the disjoint union of uncountably many \(\R^n\), can become manifold-like structure if we relax the definition.
  \end{enumerate}
\end{remark}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item \(\R^d\) covered by the single chart \(\varphi = \id\).
  \item Unit sphere \(S^n = \{\V x = (x_0, \dots, x_n) \in \R^{n + 1}: \sum_{i = 0}^n x_i^2 = 1\}\). The charts are stereographic projections
    \begin{align}
      \varphi(\V x) &= \frac{1}{1 - x_0} (x_1, \dots, x_n) \\
      \psi(\V x) &= \frac{1}{1 + x_0} (x_1, \dots, x_n)
    \end{align}
    where \(\varphi\) is defined for all points on \(S^n\) except \((1, 0, \dots, 0)\) and similar for \(\psi\). Suppose \(\varphi(P) = u, \psi(P) = v\), then by basic geometry \(v = \psi \compose \varphi^{-1}(u) = \frac{u}{\norm{u}^2}\).
  \item Given \(M_1, M_2\) manifolds of dimension of \(d_1\) and \(d_2\), \(M_1 \times M_2\) is a manifold of dimension \(d_1 + d_2\). We define the \emph{\(n\)-torus} to be \(T_n = \underbrace{S^1 \times \dots \times S^1}_{n}\).
  \item An open subset \(U\) of a manifold \(M\) is a manifold.
  \item The \emph{real projective space},
    \[
      \R P^n = \{\text{all straight lines through \(0\) in } \R^{n + 1}\}.
    \]
    The points in the space are \(x_0 : \dots : x_n\) where \(x_i\)'s are not all zero. Note that
    \[
      x_0 : \dots : x_n = \lambda x_0 : \dots \lambda x_n
    \]
    for all \(\lambda \neq 0\). As per a previous remark, we shall induce the topology by a \(C^\infty\) structure. The charts are \((U_i, \varphi_i)\) where \(U_i = \{x_i \neq 0\}\), and
    \[
      \varphi_i(x_0 : \dots : x_n) = (\frac{x_0}{x_i}, \dots, \hat i, \dots, \frac{x_n}{x_i})
    \]
    where \(\hat i\) denotes that the \(i\)th coordinate is omitted. The \(U_i\)'s cover \(\R P^n\) so we are left to check compatibility. For \(i < j\),
    \[
      \varphi_j \compose \varphi_i^{-1} : (y_1, \dots, y_n)
      \mapsto y_1 : \dots, \underbrace{1}_{i\text{th}} : y_n
      \mapsto (\frac{y_1}{y_j}, \dots, \frac{1}{y_j}, \dots, \hat j, \dots, \frac{y_n}{y_j})
    \]
    is smooth. Since \(i\) and \(j\) are arbitrary, \(\R p^n\) is a \(n\)-manifold.

    Similarly we can check \(\C P^n\) is a \(2n\)-manifold, and \(\H P^n\) is a \(4n\)-manifold (but this is a bit tricky due to noncommutativity).
  \item Grassmannians (over \(\R\) or \(\C\)): we define \(\Gr(k, n)\) to be all \(k\)-dimensional subspaces of the \(n\)-dimensional vector space, which generalises the projective space. For real vector spaces for example, \(\R P^n = \Gr(1, n + 1)\). We can check \(\Gr(k, n)\) is a manifold of dimension \(k(n - k)\).

    The construction is a bit technical so we will give example of one chart. Let \(U\) be the \(k\)-subspaces obtainable as the span of rows of \(k \times n\) matrices of the form \((I_k \quad *)\), and the local coordinate maps a basis of such \(k\)-subspace to the \(k \times (n - k)\) block \(*\). Since the frist \(k\) rows are linearly independent, we call \(U = U_{1 < 2 < \dots < k}\). More generally the domain of charts take the form \(U_{1 \leq i_1 < \dots < i_k \leq n}\). It is an exercise to check that this gives a valid \(C^\infty\) structure.
  \item A non-example: define an equivalence relation \((x, y) \sim (\lambda x, \frac{y}{\lambda})\) for all \(\lambda \neq 0\) and define \(X := \R^2/\sim\). \(\{xy = c\}\) is one equivalence class if \(c \neq 0\). If \(c = 0\), \(\{xy = 0\}\) is three classes \(\{(x, 0): x \neq 0\}, \{(0, 0)\}, \{(0, y): y \neq 0\}\). Thus
    \[
      X \cong (-\infty, 0) \cup \{0', 0'', 0'''\} \cup (0, \infty).
    \]
    Define charts
    \[
      \varphi_i: (-\infty, 0) \cup 0^{(i)} \cup (0, \infty) \to \R
    \]
    in the obvious ways. We can check that it gives \(X\) a valid \(C^\infty\) structure, except that the induced topology is non-Hausdorff!
  \item For a non-second countable example, see example sheet 1 Q12.
  \end{enumerate}
\end{eg}

\begin{definition}[smooth map]\index{smooth map}
  Let \(M, N\) be manifolds, a continuous map \(f: M \to N\) is \emph{smooth} or \(C^\infty\) if for any \(p \in M\), there exists charts \((U, \varphi)\) on \(M\), \((V, \psi)\) on \(N\) such that \(p \in U, f(p) \in V\) and
  \[
    \psi \compose f \compose \varphi^{-1}
  \]
  is smooth wherever it is defined, i.e.\ on \(\varphi(U \cap f^{-1}(V)) \subseteq \R^n\) where \(n = \dim M\).
\end{definition}

\begin{remark}
  Note that by continuity, \(\varphi(U \cap f^{-1}(V))\) is necessarily open. Of course we can do it differently by not requiring \(f\) to be continuous a priori but instead ask the above set to be open.
\end{remark}

For any charts \(\tilde \varphi, \tilde \psi\),
\[
  \tilde \psi \compose f \compose \tilde \varphi^{-1} = (\tilde \psi \compose \psi^{-1}) \compose (\psi \compose f \compose \varphi^{-1}) \compose (\varphi \compose \tilde \varphi^{-1})
\]
is a composition of smooth map so is smooth. Thus smoothness of a map is independent of charts.

\begin{definition}[diffeomorphism]\index{diffeomorphism}
  A smooth map \(f: M \to N\) is a \emph{diffeomorphism} if \(f\) is bijective and \(f^{-1}\) is smooth. If such \(f\) exists, \(M\) and \(N\) are \emph{diffeomorphism}.
\end{definition}

\begin{remark}\leavevmode
\begin{enumerate}
\item Our definition of smoothness is a generalisation of that in calculus. More precisely, \(f: \R^n \to \R^m\) is smooth if and only if it is smooth in the calculus sense.
\item Any chart \(\varphi: U \to \R^d\) is a diffeomorphism onto its image.
\item Composition of smooth maps is smooth.
\end{enumerate}
\end{remark}

\section{Matrix Lie groups}

We can view \(\GL(n, \R)\) as an array of numbers and thus embed it in \(\R^{n^2}\). Furthermore, by considering the determinant function it is an open subset so is an \(n^2\)-manifold. Matrix multiplication is obviously smooth. In the same vein we have \(\GL(n, \C)\), \(\SL(n, \R)\) etc as mannifolds with smooth multiplications.

\begin{definition}[Lie group]\index{Lie group}
  A group \(G\) is a \emph{Lie group} if \(G\) is a manifold and has a compatible group structure, i.e.\ the map \((\sigma, \tau) \mapsto \sigma\tau^{-1}\) is smooth.
\end{definition}

Before Lie groups, let's have a short digression in analysis to discuss the exponential map. For a complex \(n \times n\) matrix \(A = (a_{ij})\), define a norm
\[
  |A| = n \cdot \max_{ij} |a_{ij}|
\]
where the \(n\) in front is such that \(|AB| \leq |A| \cdot |B|\). We now define
\[
  \exp(A) := I + A + \frac{1}{2} A^2 + \dots + \frac{1}{n!} A^n + \dots
\]

Of course we have to check the series makes sense: in fact \(\exp A\) is absolutely convergent for all \(A\) as \(\left| \frac{A^n}{n!} \right| \leq \frac{|A|^n}{n!}\). The series is also uniformly convergent on any compact set, by Weierstrass \(M\)-test. Therefore \(\exp\) is a well-defined continuous map.

In fact, the map is smooth although the proof is technical. A sketch of the proof is like this: note that \(f: A \to A^m\) is smooth for all \(m \in \N\). For \(m = 2\), \(df_A: H \mapsto HA + AH\) so \(\norm{df_A} \leq 2 |A|\) so for all \(m\),
\[
  \norm{df_A} \leq m |A|^{m - 1}
\]
We can thus term-by-term differentiate \(\exp\) and get a locally uniformly convergent series and use the above estimate to bound derivatives.

It is easy to check that:
\begin{enumerate}
\item \(\exp (A^t) = (\exp A)^t\) where \(A^t\) is the transpose of \(A\).
\item \(\exp (CAC^{-1}) = C (\exp A) C^{-1}\) for \(C\) nonsingular.
\item \(\exp (A + B) \neq \exp A \exp B\) unless \(AB = BA\).
\item \(\exp A \exp (-A) = I\) for any matrix \(A\).
\end{enumerate}

The second property prompts us to put \(A\) into Jordan normal form before computing \(\exp A\).

Using the series
\[
  \log (I + A) = A - \frac{A^2}{2} + \dots + (-1)^{n + 1} \frac{A^n}{n} + \dots
\]
we can tackle this similarly to \(\exp\) to check \(\log(I + A)\) is smooth on \(\{|A| < 1\}\). We can also check
\[
  \exp (\log A) = A
\]
if \(|A - I| < 1\), with a proof given by manipulation of double indexed series, which is valid due to absolute convergence. The expression \(\log (\exp A)\) is more subtle. Clearly we need \(|\exp A - I| < 1\). But it is not sufficient: if
\[
  A_\theta =
  \begin{pmatrix}
    0 & -\theta \\
    \theta & 0
  \end{pmatrix}
\]
where \(\theta \in \R\), then
\[
  \exp(A_\theta) =
  \begin{pmatrix}
    \cos \theta & - \sin \theta \\
    \sin \theta & \cos \theta
  \end{pmatrix}
\]
Put \(\theta = 2\pi\), \(\exp A - I = 0\) but
\[
  \log (\exp A_{2\pi}) = 0 \neq A_{2\pi}.
\]
The reason is that the series is no longer absolutely convergent. If we add the additional condition that \(|A| < \log 2\) then
\[
  \log (\exp A) = A.
\]
It is left as an exercise. (Hint: \(|\exp |A| - 1| < 1\) implies absolute convergence.)

\begin{eg}[orthogonal group]
  Recall that
  \[
    O(n) = \{A \in \GL(n, \R), AA^t = I\}.
  \]
  Let \(A \in O(n)\) with \(|A - I| < 1\). Let \(B = \log A\) so \(e^B = A\). There exists \(0 < \varepsilon < 1\) such that whever \(|A - I| < \varepsilon\), have \(|B| < \log 2\) using continuity of \(\log\). Then
  \[
    e^B e^{B^t} = AA^t = I
  \]
  so
  \[
    e^B = A = (A^t)^{-1} = (e^{B^t})^{-1} = e^{-B^t}.
  \]
  Now \(|B^t| = |B| = \log 2\). Taking \(\log\), we find that \(B = -B^t\) so \(B\) is a skew-symmetric matrix.

  Conversely, if \(B = - B^t\), \(|B| < \log 2\) then
  \[
    (e^B)^t = e^{B^t} = e^{-B} = (e^B)^{-1}
  \]
  so \(A = e^B \in O(n)\).

\begin{proposition}
  \(O(n)\) has a \(C^\infty\) structure making it a manifold and Lie group of dimension \(\frac{n(n - 1)}{2}\).
\end{proposition}

\begin{proof}
  Put
  \[
    V_0 := \{B: B \text{ skew-symmetric}, |B| < \log 2\}
  \]
  and \(U := \exp (V_0)\), an open neighbourhood of \(I \in O(n)\). Let
  \begin{align*}
    h: U &\to V_0 \\
    A &\mapsto \log A
  \end{align*}
  which is a well-defined homeomorphism onto \(V_0\), an open subset of the skew-symmetric matrices, which can be identified with \(\R^{n(n - 1)/2}\).

  Now we construct the charts \((U_C, h_C)\). For all \(C = O(n)\), put \(U_C := \{CA: A \in U\}\), i.e.\ left translation of \(U\) by \(C\). Define
  \begin{align*}
    h_C: U_C &\to V_0 \\
    A &\mapsto \log (C^{-1}A)
  \end{align*}
  which is a homeomorphism % ?
  . To check they form an atlas, first note that \(C \in U_C\) so \(O(n) = \bigcup_{C \in O(n)} U_C\). Furthermore
  \[
    h_{C_2} \compose h_{C_1}^{-1} (B) = h_{C_2} (C_1 e^B) = \log (C_2^{-1}C_1 e^B)
  \]
  which is smooth since it is the composition of smooth maps. Thus \(O(n)\) is a manifold.

  To check compatibility of group axioms, define
  \begin{align*}
    F: O(n) \times O(n) &\to O(n) \\
    (A_1, A_2) &\mapsto A_1A_2^{-1}
  \end{align*}
  In local coordinates, it is
  \begin{align*}
    &h_{A_1A_2^{-1}} (F(h_{A_1}^{-1}(B_1), h_{A_2}^{-1}(B_2))) \\
    =& \log [(A_1A_2^{-1})^{-1}A_1 e^{B_1} (A_2 e^{B_2})^{-1}] \\
    =& \log (A_2 e^{B_1} e^{-B_2} A_2^{-1})
  \end{align*}
  which is smooth.
\end{proof}
\end{eg}

The same construction works for other classical groups of matrices. See example sheet 1 Q4.

\section{Tangent space to manifolds}

Consider a curve in \(\R^n\), defined by a smooth parameterisation
\[
  x(t) = (x_i(t))_{i = 1}^n
\]
such that \(x(0) = p \in \R^n\). Then a tangent to the curve is velocity
\[
  \dot x(t) \in T_p\R^n \cong \R^n.
\]
Let \(y = y(x)\) be a \(C^\infty\) change of variables, i.e.\ a local coordinates. Then
\[
  \frac{d}{dt} \Big|_{t = 0} y(x(t)) = \underbrace{\frac{D y}{D x}}_{\text{Jacobian}}(p) \dot x(0)
  = \left( \sum_{j = 1}^n \frac{\p y_i}{\p x_j} a_j \right)_{i = 1}^n
\]

\begin{definition}
  A \emph{tangent vector} \(a\) to a manifold \(M\) at a point \(p \in M\) is the assignment to each chart \((U, \varphi)\), \(p \in U\) a \(n\)-tuple \((a_1, \dots, a_n) \in \R^n\) where \(n = \dim M\) so that for another chart \((U', \varphi')\), \(p \in U'\) with local coordinates \((x_1, \dots, x_n)\) and \((x_1', \dots, x_n')\), we have
  \[
    a_i' = \sum_{j = 1}^n \frac{\p x_i'}{\p x_j} (p) a_j.
  \]
\end{definition}

This is sometimes known as the tensorial definition of tangent space. Other equivalent definitions involve flows or using derivation on germs of smooth functions.

\begin{definition}[tangent space]\index{tangent space}
  The \emph{tangent space} \(T_pM\) is the set of all tangent vectors to \(M\) at \(p\).
\end{definition}

It follows that \(T_pM\) is an \(n\)-dimensional real vector space. Thus \(T_pM \cong \R^n\) although this isomorphism is not canonical. But given a local coordinate chart with coordinates \((x_1, \dots, x_n)\), the tuple \((0, \dots, 1, \dots, 0)\) with \(1\) in \(i\)th position in \(\R^n\) has image under isomorphism \(\frac{\p}{\p x_i} (p)\). Recall the chain rule for partial derivatives:
\[
  \frac{\p}{\p x_j'} = \sum_{i = 1}^n \frac{\p x_i}{\p x_j'} \frac{\p}{\p x_i}
\]
where \((x_1', \dots, x_n')\) is another chart. This is precisely the reason we impose upon tangent vectors the transformation rule, namely so that tangent vectors become a well-defined derivation of smooth functions at \(p\): let \(a = \sum_i a_i \frac{\p}{\p x_i} (p) \in T_pM\) where \(x_i\)'s are local coordinates around \(p\). Then a first order \emph{derivation} at \(p\) is
\begin{align*}
  a: C^\infty(M) &\to \R \\
  f &\mapsto \sum_i a_i \frac{\partial f}{\partial x_i} 
\end{align*}
(where we assume the same charts on RHS) is a well-defined map independent of choice of coordinates. We can interpret, with the \(x_i\)'s,
\[
  a(f) = \frac{d}{dt} \Big|_{t = 0} f(x(t))
\]
for all \(x: (-\varepsilon, \varepsilon) \to M\) smooth, \(x(0) = p\) and \(\dot x(0) = a\).

Now for another choice \(\tilde x_i\) of local coordinates,
\[
  \frac{d}{dt} \Big|_{t = 0} f(\tilde x(t))
  = \sum_j \frac{\partial f}{\partial \tilde x_j} (p) \dot{\tilde x}_j(0)
  = \sum_{j, i} \frac{\partial f}{\partial \tilde x_j}(p) \frac{\partial \tilde x_j}{\partial x_i}(p) \dot x_i(0)
\]
by the transformation law for tangent vectors.% Thus the tensor transformation law is 

The derivations satisfy Leibniz rule, i.e.\
\[
  a(fg) = a(f)g(p) + f(p)a(g).
\]
Conversely, every linear map \(a: C^\infty(M) \to \R\) satisfying the Leibniz rule arises from some \(a \in T_pM\). This is left as an exercise.

\begin{eg}
  An example from classical differential geometry. Consider a surface \(r = r(u, v): D \to S\) where \(D \subseteq \R^2\) and \(S = r(D) \subseteq \R^3\). Then \(S\) is a manifold with \(\varphi = r^{-1}\) as a chart. Then \(r_u, r_v\) at \(p \in S\) corresponds to \(\frac{\partial}{\partial u}, \frac{\partial}{\partial v}\) in our theory.
\end{eg}

\subsection{Lie algebra}

For a Lie group, the tangent spaces get an ``infinitesimal'' version of the group multiplication.

\begin{definition}
  A \emph{Lie algebra} is a vector space with a bilinear multiplication \([\cdot, \cdot]\), i.e.\ a Lie bracket such that
  \begin{enumerate}
  \item anticommutativity: \([a, b] = -[b, a]\),
  \item Jacobi identity: \([[a, b], c] + [[b, c], a] + [[c, a], b] = 0\).
  \end{enumerate}
\end{definition}

\begin{theorem}
  Let \(G\) be a Lie group of \(n \times n\) (real or complex) matrices such that \(\log\) defines a coordinate chart near \(I \in G\), i.e.\ the image of \(\log\) near \(I\) is an open set in some real vector subspace of \(\R^{n^2}\). Identify \(\mathfrak g = T_IG\) with the above open subset. Then \(\mathfrak g\) is a Lie algebra with
  \[
    [B_1, B_2] := B_1B_2 - B_2B_1
  \]
  for \(B_1, B_2 \in \mathfrak g\).
\end{theorem}

\begin{proof}
  Check that \(\mathfrak g\) is a vector space and \([\cdot, \cdot]\) is anticommutative. The Jacobi identity holds for matrices (straightforward check).

  What is left is to show \(B_1, B_2 \in \mathfrak g\) then \([B_1, B_2] \in \mathfrak g\). Consider
  \[
    A(t) = \exp (B_1 t) \exp (B_2 t) \exp(-B_1t) \exp (-B_2t),
  \]
  the commutator of two elements in \(G\). Then \(A(0) = I\). Expand \(\exp\), we get
  \[
    A(t) = I + [B_1, B_2] t^2 + o(t^2)
  \]
  as \(t \to 0\) so
  \[
    B(t) = \log A(t) = [B_1, B_2] t^2 + o(t^2).
  \]
  In addition \(\exp B(t) = A(t)\) holds for \(|t|\) sufficiently small so \(B(t) \in \mathfrak g\) as it is in the image of the \(\log\) chart. It follows that \(\frac{B(t)}{t^2} \in \mathfrak g\) for \(t \neq 0\) as \(\mathfrak g\) is a vector space. Thus
  \[
    [B_1, B_2] = \lim_{t \to 0} \frac{B(t)}{t^2} \in \mathfrak g
  \]
  as every vector subspace of matrix \(n, \C\) is a closed subset.
\end{proof}

\begin{eg}
  For \(G = O(n)\), have \(\mathfrak g = \mathfrak o(n) = \{\text{skew-symmetric \(n \times n\) matrices}\}\) by previous work.
\end{eg}

\begin{definition}
  \(\mathfrak g\) is called the \emph{Lie algebra} of \(G\), write \(\mathfrak g = \Lie(G)\).
\end{definition}

In fact we can show \(\Lie\) is a functor but we won't pursue in that direction.

\begin{definition}[tangent bundle]\index{tangent bundle}
  Let \(M\) be a smooth manifold. Then \(TM = \coprod_{p \in M} T_pM\) is the \emph{tangent bundle} of \(M\).
\end{definition}

\begin{theorem}
  \(TM\) has a natural \(C^\infty\) structure, making it into a smooth manifold of \(\dim TM = 2 \dim M\).
\end{theorem}

\begin{proof}
  We shall induce the topology from the \(C^\infty\) structure. Let \((U, \varphi)\) be a chart on \(M\). Consider \(U_T = \coprod_{p \in U} T_pM\) so \(TM = \bigcup U_T\). For \(a \in T_pM, \varphi(p) = (x_1, \dots, x_n)\) so that \(a = \sum_i a_i \frac{\partial  }{\partial x_i}\). Now define
  \begin{align*}
    \varphi_T: U_T &\to \R^n \times \R^n \\
    a &\mapsto (\varphi(p), (a_i))
  \end{align*}

  To show compatibility, suppose \((U', \varphi')\) is another chart on \(M\) with local coordinates \(x_i'\) and efine \(\tilde \varphi'\) as above. Then
  \[
    \varphi_T' \compose \varphi_T^{-1}(x, a)
    = (x', a')
  \]
  where \(x' = \varphi' \compose \varphi^{-1}(x)\) and \(a'\) is given by the translation law
  \[
    a' = \sum_j \frac{\partial x_i'}{\partial x_j} (x) a_j,
  \]
  so is smooth wherever defined.

  Hausdorffness and second countability follows from that \(M\) and \(\R^n\) are manifolds.
\end{proof}

\begin{note}
  Some remarks on the final statement regarding topological properties:
  \begin{enumerate}
  \item \(M\) is \(\sigma\)-compact, i.e.\ every open cover has a countable subcover.
  \item A basis of topology of \(TM\) is given by \(\{B_1 \times B_2\}\) where \(B_1\) is open in some coordinate neighbourhood \(U \subseteq M\) and \(B_2\) is open in \(\R^n\).
  \end{enumerate}
\end{note}

\begin{corollary}
  The projection
  \begin{align*}
    \pi: TM &\to M \\
    (p, a) &\mapsto p
  \end{align*}
  is smooth.
\end{corollary}

\begin{remark}
  \(TM\) has locally a product structure but in general \(TM\) is not diffeomorphic to \(M \times \R^n\).
\end{remark}

\begin{definition}[vector field]\index{vector field}
  A \emph{vector field} on a manifold \(M\) is a smooth map \(X: M \to TM\) such that \(\pi \compose X = \id_M\), i.e.\ \(X(p) \in T_pM\) for all \(p \in M\).
\end{definition}

Note that \(X\) is smooth at \(p\) if and only if for any coordinate neighbourhood \(U\) of \(p\) with local coordinates \((x_1, \dots, x_n)\), \(X = \sum_{i = 1}^n a_i(x) \frac{\partial  }{\partial x}\) where \(a_i \in C^\infty(U)\) for all \(i\).

\begin{eg}
  Every manifold has at least one vector field: sending every point to \(0\). This is not the most interesting example, however.
\end{eg}

\begin{theorem}
  Suppose \(\dim M = n\). Then there exists smooth vector fields \(X^{(1)}, \dots, X^{(n)}\) on \(M\) such that for all \(p \in M\), \(X^{(1)}(p), \dots, X^{(n)}(p)\) is a basis of \(T_pM\), then \(TM\) is isomorphic to \(M \times \R^n\).
\end{theorem}

Here ``isomorphic'' means that there is a diffeomorphism \(\Phi: TM \to M \times \R^n\) such that \(\Phi|_{T_pM}: T_pM \to \{p\} \times \R^n\) is a linear isomorphism.

\begin{definition}[parallelisable]\index{parallelisable}
  A manifold satisfying the hypothesis is called \emph{parallelisable}.
\end{definition}

\begin{proof}
  Consider \(p \in M\) so \(\pi(a) = p\) for all \(a \in T_pM\). Then \(a = \sum_{i = 1}^n a_iX^{(i)}(p)\) for some unique \(a_i \in \R\). Put
  \[
    \Phi(a) := (\pi(a), (a_1, \dots, a_n)) \in M \times \R^n
  \]
  which is clearly a bijection and \(\Phi|_{T_pM}\) is a linear isomorphism. Thus suffices to check \(\Phi\) is a diffeomorphism. We use chart \((U, \varphi)\) on \(M\) and let \((\pi^{-1}(U), \varphi_T)\) be the corresponding chart on \(TM\). Then
  \[
    (\varphi, \id_{\R^n}) \compose \Phi \compose \varphi_T^{-1}:
    (x, (b_i)_{i = 1}^n) \mapsto (x, (a_i)_{i = 1}^n)
  \]
  such that
  \[
    a = \sum_i a_i X^{(i)}(p) = \sum_j b_j \frac{\p}{\p x_j}(p).
  \]
  It is then obvious that these \(a_i\)'s and \(b_j\)'s differ by a change-of-basis transformation. Explicitly, write \(X^{(i)}\) in local basis as
  \[
    X^{(i)}|_U = \sum_j X_j^{(i)} (x) \frac{\partial  }{\partial x_j}
  \]
  and so
  \[
    b_j = \sum_i a_i X_j^{(i)}(x)
  \]
  so \(\Phi\) is smooth. To check the inverse, note that \((X_j^{(i)}(x))\) is a non-singular matrix smooth in \(x\) so \(\Phi^{-1}\) also has a smooth local expression.
\end{proof}

\begin{remark}\leavevmode
  \begin{enumerate}
  \item The converse is easily seen to be true, in which case vector fields on \(M\) are simply \(C^\infty(M, \R^n)\).
  \item The parallelisable hypothesis is quite restrictive. For example, it implies that each \(X^{(i)}\) is never-zero. Some manifolds, such as \(S^2\) do not have such vector fields at all. In fact, \(S^n\) is parallelisable if only if \(n = 1, 3, 7\).
  \item Every orientable \(3\)-dimensional vector field is parallelisable.
  \end{enumerate}
\end{remark}

\begin{ex}
  Show \(S^{2n + 1}\) has a never-zero vector field.
\end{ex}

\begin{definition}[differential]\index{differential}
  Let \(F: M \to N\) be a smooth map. Then the \emph{differential} of \(F\) at \(p \in M\) is a linear map
  \[
    dF_p: T_pM \to T_{F(p)}N
  \]
  such that if \(x_i\) is a local coordinate near \(p\) and \(y_i\) is a local coordinate near \(F(p)\), then
  \[
    dF_p : \frac{\partial  }{\partial x_i} \mapsto \sum_j \frac{\partial \hat F_j}{\partial x_i}(x(p)) \frac{\partial  }{\partial y_j} (F(p))
  \]
  where \(\hat F = \psi \compose F \compose \phi^{-1}\) is the coordinate representation of \(F\).
\end{definition}

Now we have to check that it is independent of coordinate representation. Recall that
\[
  \frac{\partial  }{\partial x_k'}(p) = \sum_i \frac{\partial x_i}{\partial x_k'}(x'(p)) \frac{\partial  }{\partial x_i}(p)
\]
and similar for \(\frac{\partial  }{\partial y_j}(F(p))\). So
\[
  df_p: \frac{\partial  }{\partial x_k'}(p) \mapsto \sum_{i, j, \ell} \underbrace{\frac{\partial x_i}{\partial x_k'} \frac{\partial y_j}{\partial x_i} \frac{\partial y_\ell'}{\partial y_j}}_{\frac{\partial y_\ell'}{\partial x_k'} \text{ by chain rule}} \frac{\partial  }{\partial y_\ell'} (F(p))
\]
so \(dF_p\) is indeed invariantly defined.

\begin{ex}[geometer's chain rule]
  For \(M \xrightarrow{F} N \xrightarrow{G} Z\), we have
  \[
    d(G \compose F)_p = dG_{F(p)} \compose dF_p.
  \]
\end{ex}

Now suppose \(F: M \to N\) is a diffeomorphism and \(X\) is a vector field on \(M\). Then \((dF)X\) is a valid vector field on \(N\).

\begin{remark}
  In general a vector field does not admit a pushforward. We need surjectivity so \((dF)X\) is everywhere defined and injectivity to avoid conflicting values on target points. Finally we need the inverse to be smooth to ensure \((dF)X\) is smooth.
\end{remark}

Every vector field \(X\) defines a linear map from \(C^\infty(M)\) to itself. More precisely, it is a first order derivation with \(p \in M\) varying. Locally, if \(X = \sum_i X_i(x) \frac{\partial  }{\partial x_i}\) then \(Xh\) is given by
\[
  Xh = \sum_i X_i(x) \frac{\partial h}{\partial x_i}(x)
\]
It is an easy exercise to check that it is invariantly defined.

On the other hand, a smooth function on \(N\) can always be pulled back by \(F\). Suppose \(f \in C^\infty(N)\). Then \(f \compose F \in C^\infty(M)\). Thus in any local coordinates \(x_i\) on \(M\), \(y_i\) on \(N\), have
\[
  \frac{\partial  }{\partial x_i}(p) (f \compose F) = \sum_j \frac{\partial f}{\partial y_j} (y(F(p)) \frac{\partial y_j}{\partial x_i} (x(p)).
\]
Thus we have a coordinate-free formula
\[
  X(f \compose F) = ((dF)X f) \compose F.
\]
Equivalently, the following diagram commutes:
\[
  \begin{tikzcd}
    C^\infty(N) \ar[r, "F^*"] \ar[d, "(dF) X"] & C^\infty(M) \ar[d, "X"] \\
    C^\infty(N) \ar[r, "F^*"] & C^\infty(M)
  \end{tikzcd}
\]

Let \(X\) and \(Y\) be two vector fields on \(M\) considered as first order linear differential operators. The composition \(XY\) is \emph{not} a vector field. However,
\[
  Z := [X, Y] := XY - YX
\]
is a vector field. In local coordinates, it is
\[
  \sum_{i, k} \left( X_i \frac{\partial Y_k}{\partial x_i} - Y_i \frac{\partial X_k}{\partial x_i} \right) \frac{\partial  }{\partial x_k}
\]
where \(X = \sum_i X_i \frac{\p}{\p x_i}, Y = \sum_i Y_i \frac{\p}{\p x_i}\). Check that second order derivatives vanish (because of symmetry of mixed partials). We can check that \(Z\) is a vector field and as a map \(C^\infty(M) \to C^\infty(M)\) it is linear over \(\R\) and satisfy
\[
  Z(fg) = (Zf) g + f Zg.
\]

Thus vector fields on \(M\) form a Lie algebra, which is infinite-dimensional. Denote it by \(V(M)\).

\subsection{Left-invariant vector field}

Let \(G\) be a Lie group and \(e \in G\) the identity element. Let \(\mathfrak g = T_eG\). Given \(g \in G\), the left translation by \(g\)
\begin{align*}
  L_g: G &\to G \\
  h &\mapsto gh
\end{align*}
is a smooth map and since it has inverse \(L_{g^{-1}}\), it is a diffeomorphism.

Given \(\xi \in \mathfrak g\), we can define a vector field by
\[
  X_\xi(g) := (dL_g)_e(\xi) \in T_gG.
\]
We can do this because for every point there is a diffeomorphism sending \(e\) to it, and therefore we can construct a vector field using only its information at \(e\). We will soon find out there are lots of symmetry involved.

\begin{lemma}
  The map \(X_\xi: G \to TG, g \mapsto (dL_g)_e(\xi)\)  is smooth so \(X_\xi\) is a smooth vector field.
\end{lemma}

\begin{proof}
  As usual, check smoothness in local coordinates. Consider group multiplication \(L: G \times G \to G\). Fix \(g_0 \in G\), then around \((g_0, e) \in G \times G\), given charts \(\varphi_e\) around \(e\) whose image is \(V_e\) and \(\varphi_{g_0}\) around \(g_0\) whose image is \(V_{g_0}\), the local expression \(\hat L\) is
  \begin{align*}
    V_{g_0} \times V_e &\to V_{g_0}' \\
    \hat L &= \varphi_{g_0} (L(\varphi_{g_0}^{-1}(\cdot), \varphi_e^{-1}(\cdot)))
  \end{align*}
  Then \(\hat L_g = \hat L(\varphi_{g_0}(g), \cdot): V_e \to V_{g_0}'\).% ?
  Thus \(D_2\hat L\), the derivative of the \(V_e\) variables, gives the coordinate expression for \((dL_g)_e\). But \(D_2\hat L\) depends smoothly on the \(V_{g_0}\) variables as \(L\) is a \(C^\infty\) map. Therefore \(X_\xi\) is a smooth map around \(g_0\). As \(g_0\) is arbitrary \(X_\xi\) is smooth.
\end{proof}

We have shown that, identifying \(\mathfrak g = T_eG\), that
\[
  (dL_g)_e: \mathfrak g \to T_gG
\]
is smooth. In fact, it is a linear isomorphism. Thus we have

\begin{proposition}
  If \(\xi_1, \dots, \xi_n\) are linearly independent (form a basis, respectively) in \(\mathfrak g\) then for all \(g \in G\), \(X_{\xi_1}(g), \dots, X_{\xi_n}(g)\) are linearly independent (form a basis, respectively) in \(T_gG\).
\end{proposition}

As a consequence we have

\begin{theorem}
  Every Lie group \(G\) is parallelisable, i.e.\ \(TG \cong G \times \R^{\dim G}\) where the diffeomorphism restricts to \(T_gG\) is an isomorphism onto \(\{g\} \times \R^{\dim G}\) for all \(g \in G\).
\end{theorem}

There is another symmetry for a Lie group \(G\). For all \(g, h \in G\), for all \(\xi \in \mathfrak g\),
\[
  (dL_g)_h X_\xi(h)
  = (dL_g)_h (dL_h)_e \xi
  = (dL_{gh})_e \xi
  = X_\xi(gh),
\]
i.e.\
\[
  \label{eqn:left invariant vector field}
  (dL_g) X_\xi = X_\xi \compose L_g,
  \tag{\ast}
\]
which, if we view \(X_\xi: M \to TM\) as a global section of the projection map, may also be written as \((dL_g) X_\xi = X_\xi\).

\begin{definition}[left-invariant vector field]\index{left-invariant}
  A vector field \(X\) on a Lie group satisfying the \eqref{eqn:left invariant vector field} is called \emph{left-invariant}. Denote the subspace of all left-invariant vector fields by \(\ell(G)\).
\end{definition}

One important observation is that \(\ell(G)\) is a finite-dimensional subspace of \(V(G)\): it is easy to see that for all \(X \in \ell(G)\), there exists a unique \(\xi \in \mathfrak g\) such that \(X = X_\xi\). This induces an isomorphism \(\ell(G) \cong \mathfrak g\) so \(\dim \ell(G) = \dim G\). Even better, \(\ell(G)\) is closed under Lie bracket so

\begin{theorem}
  \(\ell(G)\) is a Lie subalgebra of \(V(G)\).
\end{theorem}

\begin{proof}
  One way to show this is to use
  \[
    X(f \compose F) = ((dF) X f) \compose F
  \]
  with \(F = L_g, X = X_\xi\) and \(f \in C^\infty(G)\). See example sheet.

  Alternatively, for any vector fields \(X, Y\) and diffeomorphism \(F\), in example sheet 1 Q6 we show that
  \[
    (dF) [X, Y] = [(dF) X, (dF) Y].
  \]
  Let \(f \in C^\infty(G), g \in G, \xi, \eta \in \mathfrak g\). Then
  \begin{align*}
    & ((dL_g) [X_\xi, X_\eta] f) \compose L_g \\
    =& ([(dL_g) X_\xi, (dL_g) X_\eta] f) \compose L_g \\
    =& ([X_\xi \compose L_g, X_\eta \compose L_g] f) \compose L_g \\
    =& (([X_\xi, X_\eta] \compose L_g) f) \compose L_g
  \end{align*}
  % why \compose L_g in the end?
  which is saying
  \[
    (dL_g) [X_\xi, X_\eta] = [X_\xi, X_\eta] \compose L_g
  \]
  which is precisely \eqref{eqn:left invariant vector field}.
\end{proof}

We now have, in the case of ``good'' matrix Lie groups, two definitions making \(\mathfrak g\) into a Lie algebra. In fact, they are equivalent.

\begin{theorem}
  Let \(G\) be a matrix Lie group with \(\log\) defining  a chart around \(e \in G\). Then
  \begin{align*}
    T_eG &\to \ell(G) \\
    \xi &\mapsto X_\xi
  \end{align*}
  is an isomorphism of the Lie algebras (using the ``matrix'' definition on LHS).
\end{theorem}
We will prove the theorem in the next chapter.

\section{Submanifolds}

Let \(M\) be a manifold, \(N \subseteq M\) and \(N\) is itself a manifold (not a priori to be have restriction of smooth structure on \(M\)). Denote \(\iota: N \to M\) the inclusion map.

\begin{definition}[embedded submanifold]\index{embedded submanifold}
  If \(\iota\) is smooth, \(d\iota_p: T_pN \to T_pM\) is injective for all \(p \in N\) and \(\iota\) is a homeomorphism onto its image, then we say \(N\) is an \emph{embedded submanifold} of \(M\).
\end{definition}

\begin{definition}[immersed submanifold]\index{immersed submanifold}
  If we drop the requirement that \(\iota\) is a homeomorphism then \(N\) is a \emph{immersed submanifold} of \(M\).
\end{definition}

At this point, the topological requirement may seem a bit mysterious and not clear what it entails. It is equivalent to the statement that \(D \subseteq N\) is open in \(N\) if and only if \(D = U \cap N\) for some \(U \subseteq M\) open. It excludes situation like mapping an open interval to figure 8.

A variant of the definition may omit \(N \subseteq M\) and instead require \(\psi: N \to M\) to be an embedding. If \(\psi\) is injective and the three properties hold then \(\psi(N) \subseteq M\) is an embedded submanifold.

\begin{convention}
  From now on submanifold means by default embedded submanifold.
\end{convention}

\begin{notation}
  For manifolds \(M\) and \(N\) and \(\psi: N \to M\) an embedding, write \(\psi: N \embed M\), i.e.\ \(\psi(N)\) is a submanifold of \(M\).
\end{notation}

\begin{remark}
  An immersion \(\psi: N \to M\) means that \(d\psi\) is injective everywhere. In this way we may obtain \(\psi(N) \subseteq M\) ``immersed with self-intersections''.
\end{remark}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item For curves and surfaces in \(\R^3\), \(\gamma: (0, 1) \to \R^3\) and \(r: U \to \R^3\) where \(U \subseteq \R^2\), the conditions mean that
    \begin{enumerate}
    \item \(\gamma\) and \(r\) are smooth,
    \item they are regular parameterisations,
    \item depending on what we are interested in, we may require them to be (topological) embeddings.
    \end{enumerate}
  \item The figure 8 example mentioned to distinguish embedded vs.\ immersed manifold may seem contrived. However, immersed (and not embedded) manifolds emerge naturally from \emph{irrational twist flow}. Consider the map
    \begin{align*}
      \R &\to S^1 \times S^1 \\
      t &\mapsto (e^{it}, e^{i\alpha t})
    \end{align*}
    where \(\alpha \in \R \setminus \Q\). We can check that the map is injective and the image is dense in \(S^1 \times S^1\). In particular it is not a toplogical emedding so this is an immersion but not an embedding.
  \end{enumerate}
\end{eg}

One frequently asked question is: is a submanifold of \(\R^n\) the same as \(f^{-1}(0)\) for some smooth map \(f: \R^n \to \R^k\)? In general, no! \(f^{-1}(0) \subseteq \R^n\) is closed. One can check that for every closed \(E \subseteq \R^2\) there exists a smooth \(f: \R^2 \to \R\) such that \(f^{-1}(0) = E\).

\begin{definition}[regular value]\index{regular value}
  Let \(f: M \to Y\) be a smooth map. \(q \in Y\) is a \emph{regular value} of \(f\) if for all \(p \in M\) such that \(f(p) = q\), \(df_p\) is surjective.
\end{definition}
Note that under this definition if \(q \notin f(M)\) then \(q\) is vacuuously a regular value of \(f\).

\begin{theorem}
  Let \(f: M \to Y\) be a smooth map and \(q \in Y\) is regular value of \(f\). If \(f^{-1}(q) \neq \emptyset\) then \(N = f^{-1}(q)\) is an embedded submanifold with
  \[
    \dim N = \dim M - \dim Y.
  \]
\end{theorem}
This is geometer's implicit function theorem, also known as preimage theorem. We assume this theorem without proof, which can be found in the lecturer's online notes.

\begin{remark}
  By a result in differential topology, suppose \(M\) is a manifold and \(N \subseteq M\) is equipped with subspace topology. If there exists a smooth structure on \(N\) such that \(N \subseteq M\) is submanifold then this structure is unique. Thus it makes sense to say \(N\) is or isn't a submanifold of \(M\).
\end{remark}

% TODO
% check this proposition and its proof

\begin{proposition}
  Let \(N \embed M\) and \(p \in N\). Then there eixsts a neighbourhood \(U\) of \(p\) in \(M\) and a smooth map \(f: U \to \R^d\) where \(d = \dim M - \dim N\) such that \(N \cap U = f^{-1}(0)\). \(d\) is called the \emph{codimension}\index{codimension} of \(N\) in \(M\).
\end{proposition}

\begin{proof}
  Let \(\varphi: U_0 \to \R^n\) is a chart on \(M\) where \(\varphi(p) = 0\) with local coordinates \((x_1, \dots, x_n)\). Let \(\psi: V_0 \to \R^\ell\) be a chart on \(N\) where \(\psi(p) = 0\) with local coordinates \((y_1, \dots, y_\ell)\). Then the inclusion \(\iota: N \to M\) has local exression
  \[
    x_i = x_i(y).
    %?
  \]
  The derivative at \(0\)
  \[
    \left( \frac{\partial x_i}{\partial y_j} (0) \right)_{n \times \ell}
  \]
  has rank \(\ell\). wlog we may assume the top \(\ell \times \ell \) submatrix is nonsingular. Then by Inverse function theorem,
  \[
    y_j = y_j(x_1, \dots x_\ell)
  \]
  which is well-defined and smooth near \(0\). Then for \(i > \ell\),
  \[
    x_i = x_i(y(x_1, \dots, x_\ell))
    = h_i(x_1, \dots, x_\ell).
  \]
  Then
  \[
    f_i(x) := x_i - h_i(x_1, \dots, x_\ell)
  \]
  for \(i > \ell\) gives a required \(f: U \to \R^d\) where \(d = n - \ell\), with Jacobian
  \[
    \frac{\partial f}{\partial x} =
    \begin{pmatrix}
      & & 1 & & 0 \\
      & * & & \vdots \\
      & & 0 & & 1
    \end{pmatrix}
  \]
  so a regular value.
\end{proof}

This result cannot be improved: let \(M = \R P^2\) and \(N = \{x_0: x_1: x_2 \in \R P^2: x_2 = 0\}\) which can be identified with \(\R P^1 \cong S^1\). But \(N \neq f^{-1}(q)\) for all smooth \(f: \R P^2 \to P\) where \(P\) is a one-dimensional manifold, with \(q\) a regular value. A sketch of proof: if there exists such an \(f\) then there exsits some chart \(\psi\) on \(U\) around \(q\), \(\psi \compose f: U \to (-1, 1)\) and \(U \supseteq N\). Suppose for contradiction \(N = \{p: (\psi \compose f) (p) = 0\}\). \(\R P^2 \setminus N\) is homeomorphic to an open disk in \(\R^2\). \(\psi \compose f\) has \(0\) as a regular value, implying that \(\psi \compose f\) takes both positive and negative values. But \(\R P^2 \setminus N\) is connected so contradiction.

\begin{theorem}[Whitney embedding theorem]\index{Whitney embedding theorem}
  Every \(n\)-dimensional manifold \(M\) admits a smooth embedding to \(\R^{2n}\).
\end{theorem}

It is a hard theorem but it is very easy to show that there exists \(N\) such that \(M\) is a submanifold of \(\R^N\). In example sheet 1 Q9 we showed this for \(M\) compact. It is also not too difficult to set \(N = 2n + 1\), basically by embedding it in a sufficiently large space and whittle down the dimension. However the last step of improvement is truely an ingenious piece of work. The remarkability of this theorem is not to say that the intrinsic defintion of manifolds coincide with the extrinsic one, but the optimal dimension \(\R^{2n}\) of ambient space. This is a topological invariant measuring how ``complicated'' a geometric object is. For example, \(S^n\) can be embedded in \(\R^{n + 1}\) but \(\R p^2\) cannot be embedded in \(\R^3\). The Klein bottle does not embed in \(\R^3\) either.

Restatement of an earlier theorem:
\begin{theorem}
  Suppose \(G \subseteq \GL(n, \C)\) is a subgroup and a Lie group with \(C^\infty\) structure of \(G\) given by \(\log\) charts (i.e.\ \(\log\) maps an open neighbourhood \(U_I\) of the idenity \(I\) onto a neighbourhood of \(0\) is some real subspace \(V_0\) of \(\operatorname{Mat}(n, \C)\)), then
  \begin{align*}
    \mathfrak g &\to \ell(G) \\
    \xi &\mapsto X_\xi
  \end{align*}
  is a Lie algebra isomorphism. Here \(\mathfrak g = T_IG \subseteq \operatorname{Mat}(n, \C)\) is the span of \(V_0\) over \(\R\).
\end{theorem}

\begin{proof}
  We have shown earlier
  \[
    [X_\xi, X_\eta] = X_\zeta
  \]
  for some \(\zeta \in \mathfrak g\). Now want to show that
  \[
    \zeta = [\xi, \eta] = \xi\eta - \eta \xi
  \]
  as \emph{matrices} in \(\mathfrak g\). First \(G = \GL(n) = \operatorname{Mat}(n)\) over \(\R\) or \(\C\) so \(\mathfrak g = mat(n)\). Then for \(g \in \GL(n)\), \(L_g\) is a linear map so \((dL_g)_h\) for all \(g, h\) in the usual matrix multiplication %?
  The local expression for \(L_g\) around \(I \in \GL(n)\) is
  \[
    (\hat L_g) B = g \cdot \exp B = g \cdot (I + B + \frac{1}{2!} B^2 + \dots)
  \]
  so
  \[
    (d \hat L_g)_0 C = gC
  \]
  Therfore for all \(g = (g^i_j) \in \GL(n), A = (A^i_j) \in \mathfrak g = T_IGL(n)\), we have
  \[
    X_A(g)
    = \sum_{i, j} X^i_j(g) \frac{\partial  }{\partial g^i_j}
    = \sum_{i, j, k} g^i_k A^k_j \frac{\partial  }{\partial g^i_j}.
  \]
  Now the chain rule follows from straightforard calculation. Using formula for Lie brackets of vector fields,
  \[
    g^i_k \left( A^k_j \frac{\partial  }{\partial g^i_j} (g^\ell_p B^p_q) - B^k_j \frac{\partial  }{\partial g^i_j} (g^\ell_p A^p_q) \right) \frac{\partial  }{\partial g^\ell_q}
    = g^i_k (AB - BA)^k_j \compose \frac{\partial  }{\partial g^i_k}.
  \]

  For the general case \(G \subseteq \GL(n)\), note that the \(\log\) chart hypothesis implies that \(\iota: G \embed \GL(n)\). In fact we'll use \(U_I \embed \GL(n)\) where \(U_I \subseteq G\). For all \(g \in G\), \(L_g: G \to G\) is the restriction of \(L_g: \GL(n) \to \GL(n)\). Furthermore for all \(h \in G\), \((dL_g)_h: T_hG \to T_{gh}G\) is the corresponding restriction of \((dL_g)_h\) on \(\GL(n)\). Therefore \(X_\xi \in \ell(G)\) is a restriction of \(X_\xi \in \ell(\GL(n))\). Then
  \[
    [X_\xi|_G, X_\eta|_G] = [X_\xi, X_\eta]|_G
  \]
  which can be verified in ``adapted'' local coordinates using local test functions only depending on coordinates along \(G\) and constant in the normal direction (graph)

  But on \(\GL(n)\) we know \([X_\xi, X_\eta] = X_{[\xi, \eta]}\), also for all \(\xi, \eta \in \mathfrak g\), \([\xi, \eta] \in \mathfrak g\). Now the theorem for \(G\) follows too.
\end{proof}

\section{Differential forms}

\begin{definition}[cotangent space]\index{cotangent space}
  Suppose \(M\) is an \(n\)-dimensional manifold and \(p \in M\). The dual of \(T_pM\), consisting of all linear funcitons \(T_pM \to \R\), is call the \emph{cotangent space} at \(p\) and denoted by \(T_p^*M\).
\end{definition}
If \(x_i\)'s are local coordinates then we have \(\frac{\p}{\p x_i}\Big|_p\) as a basis for \(T_pM\). The \emph{dual basis} of \(T_p^*M\) is denoted by \((\mathrm d x_i)_p\), i.e.
\[
  \mathrm dx_i(\frac{\partial  }{\partial x_j}) = \delta_{ij}.
\]
Therefore for all \(a \in T_p^*M\), we can express uniquely as
\[
  a = \sum_{i = 1}^n a_i (\mathrm dx_i)_p.
\]

Recall transformation rule for tangent space: if \(x_i'\) is another coodinates then
\[
  \frac{\partial  }{\partial x_i'} = \sum \frac{\partial x_k}{\partial x_i'} \frac{\partial  }{\partial x_k}
\]
so by linear algebra
\[
  \mathrm dx_i = \sum \frac{\partial x_i}{\partial x_j'} \mathrm d x_j'
\]
so if a \(1\)-form is given in two local coordinates
\[
  a = \sum_i a_i \mathrm dx_i = \sum_j a_j' \mathrm dx_j'
\]
then we have the transformation law
\[
  a_j' = \sum_i \frac{\partial x_i}{\partial x_j'} a_i
\]
which is \emph{not} the same as that for tangent space.

\begin{definition}[cotangent bundle]\index{cotangent bundle}
  The \emph{cotangent bundle} of a manifold \(M\) is defined by
  \[
    T^*M = \coprod_{p \in M} T^*_pM.
  \]
\end{definition}

\begin{theorem}
  \(T^*M\) is a smooth manifold of twice the dimension of that of \(M\). Moreover the natural projection map \(\pi: T^*M \to M\) is smooth.
\end{theorem}

\begin{proof}
  Similar to that of tangent bundle.
\end{proof}

\begin{definition}[differential \(1\)-form]\index{differential form}
  A \emph{(smooth) differential \(1\)-form}, also known as \(1\)-form \(\alpha\) is a smooth map \(\alpha: M \to T^*M\) that is a section of \(\pi: T^*M \to M\), i.e.\ \(\alpha(p) \in T_p^*M\) for all \(p \in M\).
\end{definition}

Similar to vector fields, a \(1\)-form \(\alpha = \sum_i \alpha_i \mathcal dx_i\) is smooth if and only if \(\alpha_i\) is smooth in all local coordinates, if and only if for all \(X \in V(M)\), \(\alpha(X) \in C^\infty(M)\).

To define general \(k\)-forms, we need to take a crash course in multilinear algebra. For \(r = 0, 1, \dots\), the \(r\)th \emph{exterior product}
\[
  \Lambda^r T_p^*M = \{\text{alternating multilinear functions on } (T_pM)^r\}.
\]
It is a vector space with basis
\[
  \{\mathrm dx_{i_1} \w \dots \w \mathrm dx_{i_r}\}, 1 \leq i_1 < \dots < i_r \leq n
\]
where \(n = \dim M\) and \(x_i\)'s are local coordinates around \(p\). They are defined by
\[
  \mathrm dx_{i_1} \w \dots \w \mathrm dx_{i_r} (v_1, \dots, v_r) = \det( (\mathrm dx_{i_k}(v_\ell))_{k, \ell})
\]
where \(v_\ell = \frac{\partial  }{\partial x_{k_\ell}}\) and \(k_\ell \leq k_{\ell + 1}\) for all \(\ell\). This equals to \(1\) if and only if \(v_k = \frac{\partial  }{\partial x_{i_k}}\) for all \(k\) and \(0\) otherwise.

\begin{notation}[multiindex notation]
  Let \(I = (i_1, \dots i_r)\) be a multiindex, then write
  \[
    \mathrm dx_I = \mathrm dx_{i_1} \w \dots \w \mathrm dx_{i_r}.
  \]
  Using this notation, the transformation law for \(r\)-forms under change of coordinates from \(x_i\) to \(x_j'\) is
  \[
    \mathrm dx_J' = \sum_I \prod_{k = 1}^r \frac{\partial x_{Jk}'}{\partial x_{ik}} \mathrm dx_I.
  \]
\end{notation}

Using the same method in the construction of smooth structure on \(TM\) and \(T^*M\), together with the transformation law for \(r\)-forms, we can make
\[
  \Lambda^rT^*M = \coprod_{p \in M} \Lambda^r T_p^*M
\]
into a manifold of dimension \(n = \binom{n}{r}\) with smooth projection \(\pi: \Lambda^rT^*M \to M\). It is called the \emph{bundle of differential \(r\)-forms}.

\begin{note}
  \(\Lambda^0T^*M = M \times \R\) and \(\Lambda^1T^*M = T^*M\)
\end{note}

\begin{definition}[differential form]\index{differential form}
  A \emph{smooth differential \(r\)-form}, or simply an \emph{\(r\)-form} on \(M\) is a smooth map \(\alpha: M \to \Lambda^rT^*M\) that is a section of \(\pi: \Lambda^rT^*M \to M\). The space of all \(r\)-forms on \(M\) is denoted \(\Omega^r(M)\).
\end{definition}

Given local coordinates \(x_i\)'s, a differential form \(\alpha\) can be locally expressed as
\[
  \alpha = \sum_I \alpha_I(x) \mathrm dx_I
\]
where \(\alpha_I\)'s are smooth. They can be computed by \(\alpha_I = \alpha(\frac{\partial  }{\partial x_I})\). It can be easily checked that \(\alpha\) is smooth if and only if \(\alpha(X_1, \dots, X_r)\) is smooth for all smooth vector fields \(X_1, \dots, X_r\). Note that \(0\) forms are just smooth functions \(M \to \R\) so \(\Omega^0(M) = C^\infty(M)\).

\subsection{Orientation of manifolds}

\begin{theorem}
  For an \(n\)-manifold, TFAE:
  \begin{enumerate}
  \item there exists a never-zero \(n\)-form on \(M\),
  \item there exists a family of charts \((\varphi_\alpha, U_\alpha)\) such that \(M = \bigcup U_\alpha\) and for all \(\alpha, \alpha'\) with local coordinates \(x_i, x_i'\) on \(U_\alpha, U_{\alpha'}\) respectively, we have
    \[
      \det \frac{\partial x_j'}{\partial x_i} > 0
    \]
    on \(U_\alpha \cap U_{\alpha'}\),
  \item \(\Lambda^nT^*M\) is parallelisable.
  \end{enumerate}
\end{theorem}

\begin{proof}\leavevmode
  \begin{enumerate}
  \item \(1 \implies 2\): the transformation law when a differential form is expressed in local coordinates \(x_i\) and \(x_i'\) is
    \begin{align*}
      &\mathrm dx_1 \w \dots \w \mathrm dx_n \\
      =& \left( \sum_{i_1} \frac{\partial x_1}{\partial x_{i_1}'} \mathrm dx_{i_1}' \right) \w \dots \w \left( \sum_{i_n} \frac{\partial x_n}{\partial x_{i_n}'} \mathrm dx_{i_n}' \right) \\
      =& \dots \\
      =& 
    \end{align*}
    Suppose we have \(\omega \in \Omega^n(M)\) never-zero. Let \(M = \bigcup U_\alpha\) where each \(U_\alpha\) is open connected, then
    \[
      \omega|_{U_\alpha} = f_\alpha(x^\alpha) \mathrm d x_1^\alpha \w \dots \w \mathrm dx_n^\alpha
    \]
    We can reorder \(x_i^\alpha\) such that \(f_\alpha > 0\). Then all deteminants are \(f_\alpha/f_\alpha' > 0\)
  \item \(2 \implies 1\): we need \nameref{thm:partition of unity}. Given such a collection of charts, define on each \(U_\alpha\) a never-zero \(n\)-form
    \[
      \omega_\alpha := \mathrm d x_1^\alpha \w \dots \w \mathrm dx_n^\alpha
    \]
    Let \(\{\rho_i\}\) be a partition of unity subordinate to the cover. Then
    \[
      \omega = \sum_i \rho_i (\omega_{\alpha_i})
    \]
    is a well-defined never-zero form on \(\Omega^n(M)\).
  \item \(1 \Longleftrightarrow 3\): this involves the same idea in the proof that the existence of global (co)frame is equivalent to parallisability of (co)tangent bundle. In fact, this generalises to any bundle. We omit the details.
  \end{enumerate}
\end{proof}

\begin{theorem}[partition of unity]\index{partition of unity}
  \label{thm:partition of unity}
  For every open cover \(M = \bigcup U_\alpha\), there exists a countable collection \(\rho_i \in C^\infty(M)\) such that
  \begin{enumerate}
  \item for all \(i\), \(\cl{\supp{\rho_i}}\) is compact and is contaned in \(U_\alpha\) for some \(\alpha\).
  \item locally finite: for every \(x \in M\), there exists an open neighbourhood \(W_x\) containing \(x\) such that \(\rho_i|_{W_x} \neq 0\) only for finitely many \(i\)'s.
  \item \(\rho_i \geq 0\) for all \(i\) and \(\sum_i \rho_i = 1\).
  \end{enumerate}
  Then \(\{\rho_i\}\) is a \emph{partition of unity} subordinate to \(\{U_\alpha\}\).
\end{theorem}

\begin{proof}
  Omitted.
\end{proof}

\begin{definition}[orientability]\index{orientability}
  A manifold satisfying any of the condition is called \emph{orientable}.

  If a manifold is orientable and connected then there are precisely two choices of \emph{orientation}.
\end{definition}

The orientation is induced, equivalently, by
\begin{enumerate}
\item \(\omega \in \Omega^n(M)\) up to a positive smooth function,
\item a coordinate cover up to ``positive compatibility'',
\item a choice of \(\phi\) up to composition \((x, a) \mapsto (x, h(x) a)\) where \(h \in C^\infty(M)\), \(h > 0\).
\end{enumerate}

\subsection{Exterior derivative}

Let \(M\) be a smooth manifold and \(f\) a smooth function on \(M\). The differential at a point \(p \in M\) is a linear map \(df_p: T_pM \to T_{f(p)}\R = \R\). Thus \(df_p\) can be thought as an element of \(T_p^*M\). Therefore for all \(X \in V(M)\), have
\[
  df_p(X) = Xf(p) \in C^\infty(M).
\]
By checking coeficients of \(df\) in local coordinates we find that \(df \in \Omega^1(M)\) is well-defined.

\begin{notation}
  For all local coordiates \(x_i\) defined on \(U \subseteq M\), \(\mathrm d x_i = dx_i \in \Omega^1(U)\).
\end{notation}

\begin{remark}
  This is what is called gradient in vector calculus on \(\R^n\). However, in vector calculus we identify \(\R\) with its dual, which is not always the case for manifolds. Thus gradient is a covector, or \(1\)-form.
\end{remark}

\begin{theorem}[exterior derivative]\index{exterior derivative}
  There is a unique \(\R\)-linear map \(\mathrm d: \Omega^k(M) \to \Omega^{k + 1}(M)\) for all \(k = 0, 1, \dots\) such that
  \begin{enumerate}
  \item if \(f \in \Omega^0(M)\) then \(\mathrm d f\) is the differential \(df\).
  \item \(\mathrm d(\omega \w \eta) = (\mathrm d \omega) \w \eta + (-1)^{\deg \omega} \omega \w \mathrm d \eta\) where \(\deg \omega = k\) means that \(\omega \in \Omega^k(M)\).
  \item \(\mathrm d^2 = 0\).
  \end{enumerate}
  \(\mathrm d\) is called the \emph{exterior derivative}.
\end{theorem}

\begin{proof}
  Choose \(U \subseteq M\) with local coordinates \(x_i\) and suppose \(\omega|_U = f(x) \mathrm d x_I\). Then
  \begin{align*}
    &\mathrm d(f(x) \mathrm d x_I) \\
    =& (\mathrm d f) \w \mathrm d x_I + f(x) \sum_{k = 1}^r (\dots \w (-1)^{k + 1} \mathrm d \mathrm d x_k \w \dots ) \\
    =& \sum_{i = 1}^n \frac{\partial f}{\partial x_i}(x) \mathrm d x_i \w \mathrm d x_I
  \end{align*}
  and extend to \(\Omega^r(U)\) by linearity. Then 1 clearly holds, 2 is an easy verification and 3 holds by symmetry of mixed partials. This shows the uniqueness of \(\mathrm d\).

  The above computation also shows that \(\mathrm d\) must be a local operator, i.e.\ \(\mathrm d\omega_p\) is determined by \(\omega|_U\) for any coordinate neighbourhood \(U\) of \(p\). Thus for existence of \(\mathrm d\) it suffices to check if given another local coordinates \(x_i'\) on \(U\), the two local expressions agree. Suppose \(\mathrm d'\) is the exterior derivative given by another coordinates \(x_i'\) on \(U\). Aim to show \(\mathrm d' = \mathrm d\) on \(\Omega^r(U)\) for all \(r\).
  \[
    \mathrm d' (f \mathrm d x_I)
    = \mathrm d'f \w \mathrm d x_I + \sum_{k = 1}^r (-1)^{k + 1} f \mathrm d x_{i_1} \w \dots \w \mathrm d' \mathrm d x_{i_k} \w \dots \w \mathrm d x_i
  \]
  \(\mathrm d' f = \mathrm d f\) as \(f\) is a \(0\)-form and \(\mathrm d' x_{i_k} = \mathrm d x_{i_k}\) as \(x_{i_k}\) are smooth functions. Finally,
  \[
    \mathrm d' \mathrm d x_{i_k} = \mathrm d \mathrm d x_{i_k} = 0
  \]
  so \(\mathrm d (f \mathrm dx_I) = \mathrm d'(f \mathrm dx_I)\). \(\mathrm d = \mathrm d'\).
\end{proof}

\subsection{Pullback of differential forms}

\begin{definition}[pullback]\index{pullback}
  Let \(f: M \to N\) be a smooth map. Then the \emph{pullback} induced by \(f\) is
  \begin{align*}
    f^*: \Omega^r(N) &\to \Omega^r(M) \\
    \alpha &\mapsto f^*(\alpha)
  \end{align*}
  where
  \[
    (f^*(\alpha))_p (v_1, \dots, v_r) = \alpha_{f(p)} ((df_p) v_1, \dots, (df_p)v_r)
  \]
  for all \(p \in M, v_i \in T_pM\).
\end{definition}

\begin{note}\leavevmode
  \begin{enumerate}
  \item Unlike vector fields which in general cannot be pushed forward unless \(f\) is a diffeomorphism, \(f^*\) is well-defined for all maps \(f\).
  \item Chain rule for pullbacks: given \(Z \xrightarrow{g} M \xrightarrow{f} N\) then \((f \compose g)^* = g^* \compose f^*\), i.e.\ pullback is a contravariant functor.
  \item \(f^*(\alpha \w \beta) = f^*(\alpha) \w f^*(\beta)\) which is a straightforward exercise. In particular for all \(h \in C^\infty(N)\),
    \[
      f^*(h \alpha) = (h \compose f) f^*(\alpha)
    \]
    which implies that \(f^*\) is \(C^\infty(M)\)-linear.
  \item Exterior derivative commutes with pullbacks, i.e.\ \(\mathrm d (f^*\alpha) = f^*(\mathrm d \alpha)\). For a proof, suffices to check this on \(\R^n\) as \(\mathrm d\) is local and \(f^*\) is pointwise (i.e.\ algebraic). The outline is as follow: wlog \(M = U \subseteq \R^n\) and \(N = V \subseteq \R^m\) open. Let the local coordinates be \(x_i\) and \(y_j\) respectively. For \(\alpha = \mathrm dy_j, v = \frac{\partial  }{\partial x_k}\) and local coodinate for \(f\) is \(y_j = y_j(x)\), have
    \begin{align*}
      &(f^* (\mathrm d y_j)) (\frac{\partial  }{\partial x_k}) \\
      =& \mathrm d y_j ((df) \frac{\partial  }{\partial x_k}) \\
      =& \mathrm d y_j (\sum_\ell \frac{\partial y_\ell}{\partial x_k} \frac{\partial  }{\partial y_\ell}) \\
      =& \sum_\ell \frac{\partial y_\ell}{\partial x_k} \delta_{j \ell} \\
      =& \frac{\partial y_j}{\partial x_k}
    \end{align*}
    so \(f^*\) is determined by its images on \(\mathrm dy_j\).
  \end{enumerate}
\end{note}

\subsection{de Rhan cohomology}

We can use exterior derivatives to form a sequence
\[
  \Omega^0(M) \xrightarrow{d_0} \Omega^1(M) \xrightarrow{d_1} \Omega^2(M) \xrightarrow{d_2} \dots
\]
with \(d_{n + 1} \compose d_n = 0\) for all \(n\). In fact this is a sequence of \(\R\)-vector space homomorphisms.

\begin{definition}[closed form, exact form]\index{closed form}\index{exact form}
  If \(\alpha \in \Omega^r(M)\) is such that \(\mathrm d \alpha = 0\) then \(\alpha\) is a \emph{closed form}. If \(\alpha = \mathrm d \beta\) for some \(\beta \in \Omega^{r - 1}(M)\) then \(\alpha\) is an \emph{exact form}.
\end{definition}

Clearly exact forms are closed but the converse is not true in general. Thus it makes sense to consider

\begin{definition}[de Rham cohomology]\index{de Rham cohomology}
  The quotient space
  \[
    H^r_{\text{dR}}(M) = \frac{\ker d_r}{\im d_{r - 1}},
  \]
  sometimes also denoted \(H^r(M)\), is called the \emph{de Rham cohomology} (or degree \(r\)) of \(M\).
\end{definition}

As \(f^*\) commutes with \(\mathrm d\), \(f^*\) is a well-defined map on \(H^r(M)\) and chain rule holds. Hence for \(M\) diffeomorphic to \(N\), we have
\[
  H^r(M) \cong H^r(N)
\]
for all \(r\). The inverse, however, is not true.

We can define
\[
  H^*_\text{dR}(M) = \bigoplus_{r = 0}^\infty H^r_{\text{dR}}(M).
\]
It is an easy exercise to check that wedge product induces a ring structure on \(H^*_{\text{dR}}(M)\) (the key point is that \((\mathrm d \alpha) \w \beta = \mathrm d(\alpha \w \beta)\) whenever \(\mathrm d \beta = 0\)). Moreover, assume \(M\) is connected, \(H^r_{\text{dR}}(M)\) is finite-dimensional as \(\Omega^r(M)\) vanishes for \(r > \dim M\), so does \(H^r_{\text{dR}}(M)\).

For all smooth \(f: M \to N\), the pullback \(f^*\) induces a well-defined ring homomorphism \(f^*: H^*(N) \to H^*(M)\). From previous work, have

\begin{proposition}
  If \(M\) is diffeomorphism to \(N\)  then
  \[
    H^*(M) \cong H^*(N).
  \]
\end{proposition}

Again the converse is false. Try to show that
\[
  H^*(\R P^3) \cong H^*(S^3).
\]

There are many types of (co)homologies on a space. The important result is

\begin{theorem}[de Rham]\index{de Rham theorem}
  Given a smooth manifold \(M\),
  \[
    H^r_{\text{dR}}(M) \cong H^r(M, \R)
  \]
  where \(H^r(M, \R)\) is the singular cohomology of \(M\) with coefficients in \(\R\).
\end{theorem}

This tells us that \(H^r_{\text{dR}}(M)\) recovers an invariant of the topological space underlying \(M\), using differential \(r\)-forms.

If \(M\) is connected then \(H^0_{\text{dR}}(M) \cong \R\), i.e.\ the constant functions on \(M\). For more generally result, we need

\begin{theorem}[Poincar lemma]\index{Poincar lemma}
  \label{thm:Poincar lemma}
  Let \(U\) be the unit open ball in \(\R^n\). Then every closed \(k\)-form, where \(k > 0\), is exact.
\end{theorem}

\begin{corollary}
  \[
    H^k(U) =
    \begin{cases}
      0 & k > 0 \\
      \R & k = 0
    \end{cases}
  \]
\end{corollary}

In fact, we can replace \(U\) by \(\R^n\) and get the same result.

\begin{proof}[Proof of \nameref{thm:Poincar lemma}]
  We give a sketch of proof. The key idea of is that we can invert \(\mathrm d_k\)'s using integral operators
  \[
    h_k: \Omega^k(U) \to \Omega^{k - 1}(U)
  \]
  for \(k > 0\) such that
  \[
    h_{k + 1} \compose \mathrm d_k + \mathrm d_{k - 1} \compose h_k = \id_{\Omega^k(U)}.
  \]
  Explicitly, define
  \begin{align*}
    & h_k(a \mathrm dx_{i_i} \w \dots \w \mathrm dx_{i_k}) (v_1, \dots, v_{k - 1}) \\
    =& \left(\int_0^1 t^{k - 1} a(tx) dt \right) \mathrm d x_{i_1} \w \dots \w \mathrm dx_{i_k} \left(\sum_{i = 1}^k x_i \frac{\partial  }{\partial x_i}, v_1, \dots v_{k - 1}\right).
  \end{align*}
\end{proof}

\subsection{Basic integration on manifolds}

In this section assume \(M\) is an oriented \(n\)-manifold, where the orientation is given by a choice of positively compatible charts \(\{(\varphi_\alpha, U_\alpha)\}\).

Let \(\omega \in \Omega^n(M)\) and define its support to be
\[
  \supp \omega = \{p \in M: \omega(p) \neq 0\}.
\]
Assume the closure \(\cl{\supp \omega}\) is comapct. If \(\cl{\supp \omega} \subseteq U_\alpha\) for some \(\alpha\) with local coordinates \(x_i\) and
\[
  \omega|_{U_\alpha} = f(x) \mathrm dx_1 \w \dots \w \mathrm dx_n,
\]
then define
\[
  \int_M \omega = \int_{\varphi_\alpha(U_\alpha)} f(x) dx_1 \dots dx_n
\]
where RHS is the Riemann integral on \(\R^n\). To show this is well-defined, suppose \(\cl{\supp \omega} \subseteq U_\beta\) for some \(\beta\) with coordinates \(y_j\), and
\[
  \omega|_{U_\alpha \cap U_\beta} = h(y) \mathrm dy_1 \w \dots \w \mathrm d y_n.
\]
Then
\begin{align*}
  \int_{\varphi_\beta(U_\beta)} h(y) dy_J
  = \int_{\varphi_\alpha(U_\alpha)} h(y(x)) \Bigg| \det \frac{D y}{D x} \Bigg| d x_I
  = \int_{\varphi_\alpha(U_\alpha)} f(x) dx_I
\end{align*}

To define the intergral of a differential form that is not supported on a single chart, we use partition of unity.

\begin{definition}[integration on manifold]\index{integration on manifold}
  Suppose \(\{\rho_i\}\) is a partition of unity subordinate to the oriented cover. Then define
  \[
    \int_M \omega = \sum_i \int_{U_i} \rho_i \omega.
  \]
\end{definition}

Some basic properties of the integral whose proofs will be left as exercises:
\begin{enumerate}
\item it is linear in \(\omega\),
\item it is additive over disjoint coordinate neighbourhoods,
\item it is independent of choice of partition of unity (hint: if \(\{\rho_i\}\) and \(\{\tilde \rho_j\}\) are two partitions of unity then show \(\{\rho_i \tilde \rho_j\}\) is another).
\end{enumerate}

\begin{theorem}[Stoke's theorem for manifolds without boundary]\index{Stoke's theorem}
  If \(\eta \in \Omega^{n - 1}(M)\) is compactly supported then
  \[
    \int_M \mathrm d \eta = 0.
  \]
\end{theorem}

\begin{proof}
  Let \(\{U_i\}_{i = 1}^N\) be positively compatible coordinate neighbourhoods covering \(\cl{\supp \eta}\) and let choose charts on \(U_0 = M \setminus \cl{\supp \eta}\) so that it is positively compatible with \(U_i\) for \(1 \leq i \leq N\). Then \(\{U_i\}_{i = 0}^N\) define an orientation on \(M\). Let \(\{\rho_i\}\) be a partition of unity subordinate to \(\{U_i\}_{i = 0}^N\) and let
  \[
    \mathrm d \eta = \sum_{i = 0}^N \mathrm d(\rho_i \eta)
  \]
  be an \(n\)-form. Suffices to prove that for all \(i\),
  \[
    \int_M \mathrm d (\rho_i \eta) = 0.
  \]
  Fix \(i\) and let \(x_k\) be coordiantes on \(U_i\). wlog
  \[
    \rho_i \eta = h \mathrm dx_1 \w \dots \w \mathrm dx_n
  \]
  so
  \[
    \mathrm d(\rho_i \eta) = \frac{\partial h}{\partial x_1} \mathrm dx_2 \w \dots \w \mathrm dx_n.
  \]
  As \(\supp h\) is bounded, say by \(R\), have
  \begin{align*}
    & \int_{\R^n} d(\rho_i \eta) \\
    =& \int_{\R^{n - 1}} (\int_{-R}^R \frac{\partial h}{\partial x_1} \mathrm dx_1) dx_2 \dots dx_n \\
    =& \int_{\R^{n - 1}} \underbrace{h(R, x_2, \dots, x_n)}_{= 0}- \underbrace{h(-R, x_2, \dots, x_n)}_{= 0} dx_2 \dots dx_n \\
    =& 0
  \end{align*}
\end{proof}

\begin{corollary}[integration by parts]
  Assume one of the forms \(\alpha, \beta\) is compactly supported on \(M\) and \(\deg \alpha + \deg \beta + 1 = \dim M\). Then
  \[
    \int_M \alpha \w \mathrm d\beta = (-1)^{1 + \deg \alpha} \int_M (\mathrm d\alpha) \w \beta.
  \]
\end{corollary}

\begin{proof}
  Apply Stoke's theorem to \(\eta = \alpha \w \beta\).
\end{proof}

\section{Vector bundles}

\begin{definition}[submersion]\index{submersion}
  A smooth map \(f: M \to N\) is a \emph{submersion} if \(d f_x: T_xM \to T_{f(x)}N\) is surjective for all \(x \in M\).
\end{definition}

\begin{definition}[vector bundle]
  A \emph{vector bundle} over a manifold \(B\) is a smooth submersion \(\pi: E \to B\) of a manifold \(E\) onto \(B\) satisfying
  \begin{enumerate}
  \item there exists a vector space \(V\) such that for all \(p \in B\), \(E_p := \pi^{-1}(p)\) is a vector space isomorphic to \(V\);
  \item local trivailisation: for every \(p \in B\), there exists open neighbourhood \(U\) of \(p\) and a diffeomorphism \(\Phi_U\) such that the diagram
    \[
      \begin{tikzcd}
        \pi^{-1}(U) \ar[r, "\Phi_U"] \ar[dr, "\pi"] & U \times V \ar[d] \\
        & U
      \end{tikzcd}
    \]
    commutes, where the map \(U \times V \to U\) is projection to first coordinate;
  \item \(\Phi_p: E_p \to \{p\} \times V\) is an isomorphism of vector spaces for all \(p \in U\).
  \end{enumerate}
  \(B\) is called the \emph{base} of the bundle and \(E\) is called the \emph{total space}. \(V\) is called \emph{typical bundle} and \(\dim V\) is the \emph{rank} of the vector bundle. \(\pi\) is the bundle projection. \(\Phi_U\) is a \emph{local trivialisation} and \(U\) is a \emph{trivialising neighbourhood}.
\end{definition}

Vector bundles of rank \(1\) are also called \emph{line bundles}\index{line bundle}.

\begin{definition}[section]\index{section}
  A \emph{section} of a vector bundle \(E\) is a smooth map \(s: B \to E\) such that \(\pi \compose s = \id_B\).

  A \emph{local section} \(s: N \to E\) where \(N \subseteq B\) is a smooth map such that \(\pi \compose s = \id_N\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item For any manifold \(V\) and vector space \(V\), take \(E = B \times V\) and \(\pi\) to be the projection onto first coordinate. This is known as a \emph{trivial bundle} or \emph{product bundle}. Sections of this bundle are \(C^\infty(B, V)\), i.e.\ vector valued functions on \(B\).
  \item (Co)tangent bundles \(TM, T^*M\) are real vector bundles of rank \(\dim M\). Sections are \(V(M)\) and \(\Omega^1(M)\) respectively. More generally, \(\Lambda^rT^*M\) is a real bundle of rank \(\binom{n}{r}\) and sections are differential \(r\)-forms \(\Omega^r(M)\). If \(r = 0\) then the bundle is trivial.
  \item Tautological vector bundle\index{tautological vector bundle} over \(\R P^n, \C P^n\) and more generally Grassmannians: set \(B = \C P^n\) and \(E\) to be the disjoint union of all complex lines in \(\C^{n + 1}\) through \(0\) and \(\pi\) maps \(z \in E\) to the complex line containing \(z\) in \(\C P^n\). We'll check that this is a well-defined line bundle.
  \end{enumerate}
\end{eg}

\subsection{Structure group and transition functions}

Let \((U_\alpha, \varphi_\alpha)\) and \((U_\beta, \varphi_\beta)\) be two local trivialising neighbourhoods with \(U_\alpha \cap U_\beta \neq \emptyset\). Then
\[
  \varphi_\beta \compose \varphi_\alpha^{-1}(b, v) = (b, \psi_{\beta\alpha}(b)(v))
\]
for all \((b, v) \in (U_\alpha \cap U_\beta) \times V\), where \(\psi_{\beta\alpha}: U_\alpha \cap U_\beta \to \GL(V)\) is smooth. We have
\begin{align*}
  \psi_{\alpha\alpha} &= \id_V \\
  \psi_{\alpha\beta} \cdot \psi_{\beta\alpha} &= \id_V \\
  \psi_{\alpha\beta} \cdot \psi_{\beta\gamma} \cdot \psi_{\gamma\alpha} &= \id_V
\end{align*}
which are called the \emph{cocycle} conditions. \(\psi_{\beta\alpha}\) are called the \emph{transition functions} of the vector bundle \(E\).

\begin{eg}
  When \(E = TM\) or \(T^*M\), \(\psi_{\beta\alpha}\) are given by the Jacobian matrices of a change of local coordinates (they are daul to each other).
\end{eg}

\begin{proposition}
  The data of \(B\) and \(\{(U_\alpha, \psi_{\beta\alpha})\}\) with \(B = \bigcup U_\alpha\) determines a vector bundle \(E\) uniquely up to isomorphism (which we will define formally later).
\end{proposition}

\begin{proof}
  The proof is called \emph{Steenrod construction}. Define
  \[
    E := \left(\coprod_\alpha U_\alpha \times V\right) / \sim
  \]
  where the equivalence relation is the one generated by \((b, v) \sim (b, \psi_{\beta\alpha}(b)(v))\) for all \(b \in U_\alpha\) for all \(\alpha, \beta\). \(E\) is a manifold as \(\sim\) is a diffeomorphism. wlog \(U_\alpha \subseteq B\) are coordinate neighbourhoods with charts \(\varphi_\alpha\). Then \(\Phi_\alpha = (\varphi_\alpha, \id)\) are charts for \(E\). Finally, \(\pi: E \to B, (b, v) \mapsto b\) is a smooth submersion.
\end{proof}

\begin{definition}[\(G\)-structure]\index{\(G\)-strucure}
  Let \(E\) be a real vector bundle over \(B\). Let \(G \leq \GL(k, \R)\). A collection of charts \(\{(U_\alpha, \varphi_\alpha)\}\) covering \(B\) such that the corresponding \(\psi_{\beta\alpha}(b) \in G\) for all \(\alpha, \beta\) is called a \emph{\(G\)-structure}. If \(E = TM\), we say \(E\) is a \(G\)-structure on \(B\).
\end{definition}

\begin{eg}\leavevmode
  \begin{enumerate}
  \item If \(G\) is the trivial subgroup then a \(G\)-structure is a global trivialisation over \(B\), i.e.\ \(\Phi: E \to B \times \R^k\) is a local trivilisation on \(U = B\).
  \item If \(G = \GL_+(k, \R)\), the linear isomorphisms with positive determinant, then a \(G\)-structure is an orientation of \(E\). For example, if \(E = TM\) then this gives an orientation of \(M\).
  \item If \(G = O(k)\) (or \(G = U(k)\) in case of complex bundle) then it determines a choice of invariantly defined inner product on fibres of \(E\) smoothly varying with the fibre. \(\Phi_\alpha\) are then called \emph{orthogonal (unitary respectively) trivialisations}. In this case given a trivialisation \(\Phi_{U_\alpha}: \pi^{-1}(U_\alpha) \to U_\alpha \times \R^n\) and \(b \in U_\alpha\), the linear isomorphism \(\Phi_{U_\alpha}|_b: \pi^{-1}(b) \to \{b\} \times \R^n\) is moreover a linear isometry.

    If we set instead \(G = SO(k) = O(k) \cap \GL_+(k, \R)\) we get an orthogonal trivialisation together with an orientation.
  \item Suppose \(E\) is a real vector bundle of rank \(k = 2n\) and take
    \[
      G = \GL(n, \C) \subseteq \GL(2n, \R),
    \]
    then for all \(p \in B\), there exists \(J_p \in \GL(E_p)\) such that \(J^2 = -\id_{E_p}\) which depends smoothly on \(p\). In other words, \((E_p, J_p)\) is isomorphic to a complex vector space of dimension \(n\). This \(G\)-structure makes \(E\) into a \emph{complex vector bundle}\index{vector bundle!complex}. Note that this is \emph{not} the same as complex manifold, which has a stronger requirement. When \(E = TM\) then a \(\GL(n, \C)\)-structure on \(E\) is called an \emph{almost complex structure}\index{almost complex structure}.
  \end{enumerate}
\end{eg}

Generally, if \(G \leq \GL(V)\) preservse some ``linear algebra objects'' on \(V\) then \(G\)-structure on a vector bunldes means there exists a well-defined family of such objects depend smoothly on the point in the base.

\subsection{Principal bundles}

Let \(G\) be a Lie group, \(1_G\) the identity element of \(G\). Let \(P, B\) be manifolds.

\begin{definition}[smooth free right action]\index{smooth free right action}
  A \emph{smooth free right action} is a right action of a Lie group on a manifold that is also free. Concretely, a smooth free right action of \(G\) on \(P\) is a smooth map
  \begin{align*}
    P \times G &\to P \\
    (p, h) &\mapsto ph
  \end{align*}
  satisfying
  \begin{enumerate}
  \item free action: for all \(p \in P\), \(ph = p\) if and only if \(h = 1_G\).
  \item right action: for all \(p \in P, h_1, h_2 \in G\), \((ph_1)h_2 = p(h_1h_2)\).
  \end{enumerate}
\end{definition}

\begin{note}
  The right action implies that for all \(h \in G\), \(p \mapsto ph\) is a diffeomorphism of \(P\) to itself.
\end{note}

\begin{definition}[principal bundle]\index{principal bundle}
  A \emph{principal \(G\)-bundle} of \(P\) over \(B\) is a smooth submersion \(\pi: P \to B\) with a smooth free right action of \(G\) on \(P\) such that the set of orbits is bijective with \(B\) ``naturally'': for all \(b \in B\), there exists an open neighbourhood \(U\) of \(b\) with a diffeomorphism \(\Phi_U\) such that
  \[
    \begin{tikzcd}
      \pi^{-1}(U) \ar[r, "\Phi_U"] \ar[dr, "\pi"] & U \times G \ar[d] \\
      & U
    \end{tikzcd}
  \]
  commutes, where \(U \times G \to U\) is projection to first coordinate. Moreover \(\Phi_U\) commutes with \(G\)-action, i.e.
  \[
    \Phi_U(ph) = (b, gh)
  \]
  whenever \(b = \pi(p) \in U, \Phi_U(p) = (b, g)\).

  \(P\) is the \emph{total space}, \(B\) is the \emph{base} and \(G\) is the \emph{fibre}.
\end{definition}

\begin{note}
  Principal \(G\)-bundle is not the same as a locally trivial bundle with fibres being a Lie group. It also incorporates information about group action.
\end{note}

Similar to vector bundles, given charts on two trivialising neighbourhoods, have
\[
  \varphi_\beta \compose \varphi_\alpha^{-1} (b, g) = (b, \psi_{\beta\alpha}(b, g))
\]
where \(\psi_{\beta\alpha}(b, \cdot): G \to G\). The \(G\)-equivariant condition then implies that
\[
  \psi_{\beta\alpha}(b, g) = \psi_{\beta\alpha}(b) g = L_{\psi_{\beta\alpha}(b)} g
\]
where \(L_h : G \to G\) is left multiplication by an element \(h\) and \(\psi_{\beta\alpha}(b) = \psi_{\beta\alpha} (b, 1_G)\).
As before, the transition functions \(\psi_{\beta\alpha}: U_\alpha \cap U_\alpha \to G\) are smooth maps satisfying the cocycle conditions.

We can also recover a principal \(G\)-bundle from the transition functions, up to \(G\)-bundle isomorphism:

\begin{theorem}
  Given \(\{(U_\alpha, \psi_{\beta\alpha})\}\) such that \(B = \bigcup U_\alpha\) and \(\psi_{\beta\alpha}\)'s satisfy the cocycle conditions, let
  \[
    P := \left(\coprod_\alpha U_\alpha \times G \right) / \sim
  \]
  where \((b, h) \sim (b', h')\) if and only if \(b = b', h' = \psi_{\beta\alpha}(b)h\). Then \(P\) is a principal \(G\)-bundle over \(B\).
\end{theorem}

\begin{proof}
  Same as before.
\end{proof}

\begin{remark}
  The orbit space can be made into a manifold with an additional assumption: if the action of \(G\) is also \emph{proper}, i.e.\ the map
  \begin{align*}
    G \times P &\to P \times P \\
    (g, p) &\mapsto (pg, p)
  \end{align*}
  is a proper map (preimage of compact set is compact) then can show \(P/G\) is a smooth manifold. Then may define \(B = P/G\).
\end{remark}

The consequence of the above theory is that we can start from a vector bundle \(E\) with a \(G\)-structure, and use \(\{\psi_{\beta\alpha}\}\) to obtain a principal \(G\)-bundle \(P\) with the same transition functions. Conversely, given a principal \(G\)-bundle \(P\), we say \(G\) is \emph{associated} to \(P\) via the action of \(G\) on \(\R^n\) where \(n\) is the rank of \(E\), i.e.\ this is a \emph{representation} \(G \to \GL(n, \R)\), an injective homomorphism.

In the case of principal \(G\)-bundle, \(G\) acts on itself by \emph{left translation}.

\begin{eg}
  Let \(E = TM\) then \(P\) is a \emph{frame bundle}\index{frame bundle}, \(G = \GL(n, \R)\). For all \(p \in P\), it is a basis of \(T_{\pi(p)}M\).

  If in addition \(TM\) has \(O(n)\)-structure then obtain \(P\) the \emph{orthonormal frames bundle}.
\end{eg}

\subsection{Hopf bundle}

A Hopf bundle is an example of a tautological rank 1 complex vector bundle over \(\C P^1\). Recall that the fibre over \(z_1 : z_2 \in \C P^1\) is the line \(\C(z_1, z_2) \subseteq \C^2\).

We shall work out the transition functions to prove this vector bundle is well-defined. Let
\[
  U_i = \{z_i \neq 0\} \subseteq \C P^1
\]
and let \(z = \frac{z_2}{z_1}\) be a local coordinate on \(U_1\), \(\zeta = \frac{z_1}{z_2}\) on \(U_2\). Every point in fibre over \(1: z \in U_1\) can be written as \((w, wz)\) where \(w \in \C\), and respectively as \((w\zeta, w)\) over \(\zeta: 1 \in U_2\). The local trivialisations over \(U_i\) are
\begin{align*}
  \varphi_1: \pi^{-1}(U_1) &\to U_1 \times \C \\
  (w, wz) &\mapsto (1 : z, w \sqrt{1 + |z|^2}) \\
  \varphi_2: \pi^{-1}(U_2) &\to U_2 \times \C \\
  (w\zeta, w) &\mapsto (\zeta : 1, w \sqrt{|\zeta|^2 + 1})
\end{align*}
then
\[
  \varphi_1^{-1}(1: z, \tilde w) = \left( \frac{\tilde w}{\sqrt{1 + |z|^2}}, \frac{\tilde w}{\sqrt{1 + |z|^2}} z \right)
\]
if \(z \neq 0\) then
\begin{align*}
  \varphi_2 \compose \varphi_1^{-1}(1 : z, \tilde w)
  &= \varphi_2 \left( \frac{\tilde w}{\zeta \sqrt{1 + 1/|\zeta|^2}} \zeta, \frac{\tilde w}{\zeta{ }\sqrt{1 + 1/|\zeta|^2}} \right) \\
  &= (\zeta : 1, \frac{|\zeta|}{\zeta} \tilde w) \\
  &= (1 : z, \frac{z}{|z|} \tilde w)
\end{align*}
by noting that \(\zeta z = 1\). Thus the transition functions are
\begin{align*}
  \psi_{2, 1}(1 : z) & = \frac{z}{|z|} \\
  \psi_{1, 2}(\zeta: 1) &= \frac{|z|}{z} = \frac{\zeta}{|\zeta|}
\end{align*}
Observe
\[
  \psi_{2, 1}: U_1 \cap U_2 \to U(1) = \{a \in \C: |a| = 1\} \subseteq \C^* = \GL(\C)
\]
so the Hopf-bundle is well-defined and admits a \(U(1)\)-structure. Thus it has an invariantly defined norm on the fibres, induced from standard Euclidean norm on \(\C \subseteq \C^2\) via \(\varphi_1, \varphi_2\). More explicitly, on \(\pi^{-1}(U_1)\),
\[
  \norm{(w, wz)} = |w| \sqrt{1 + |z^2|}.
\]
Leave as an exercise to write out the expression for \(\pi^{-1}(U_2)\), and verify that it gives the same norm.

The associated principal \(U(1)\)-bundle \(P\), also known as \emph{Hopf bundle}\index{Hopf bundle}, is the bundle of unit vectors. Thus
\[
  P \cong \{(w_1, w_2) \in \C^2: |w_1|^2 + |w_2|^2 = 1\} = S^3
\]
and
\begin{align*}
  \pi: S^3 &\to \C P^1 \\
  (w_1, w_2) &\mapsto w_1 : w_2
\end{align*}
But recall from example sheet 1 Q5 that \(\C P^1 \cong S^2\) so \(\pi: S^3 \to S^2\). Together with some topological argument, we see that the Hopf bundle cound not be a product bundle
\[
  S^3 \cong S^2 \times S^1.
\]
See example sheet 2 Q5.

\begin{definition}[local section]\index{local section}\index{section!local}
  A \emph{local section} of a principal bundle \(\pi: P \to B\) is a smooth map \(s: W \to P\), where \(W \subseteq B\) open, such that \(\pi \compose s = \id_w\).
\end{definition}

There is nothing new in the dfinition here --- we have seen local and global sections for vector bundles before. However, note that although every vector bundle admits a global section, namely the zero section, it is not true for principal bundles. We cannot choose the ``identity element section'' as there is no distinguished point in a fibre. In fact, a principal bundle admits a global section if and only if it is trivial.

\subsection{Pullback of a vector bundle or a principal bundle}

\begin{definition}[pullback of a vector bundle]\index{pullback}\index{vector bundle!pullback}\index{principal bundle!pullback}
  Let \(\pi: E \to B\) be a vector bundle and \(f: M \to B\) be a smooth map. The \emph{pullback} \(f^*E\) of \(E\) is a vector bundle over \(M\) with same fibre \(V\) as \(E\) and such that there exists smooth \(F\) making the diagram
  \[
    \begin{tikzcd}
      f^*E \ar[r, "F"] \ar[d, "\tilde \pi"] & E \ar[d, "\pi"] \\
      M \ar[r, "f"] & B
    \end{tikzcd}
  \]
  commutes, and the restriction \(F: (f^*E)_p \to E_{f(p)}\) to fibres is an isomorphism of vector spaces for all \(p \in M\).
\end{definition}

It follows that for all local trivialisations of \(E\) over \(U\), we must have
\[
  \begin{tikzcd}
    \pi^{-1}(U) \ar[r, "\Phi_U"] & U \times V \\
    \tilde \pi^{-1}(f^{-1}(U)) \ar[u, "F"] \ar[r, "\tilde \Phi_U"] & f^{-1}(U) \times V \ar[u, "f \times \id_V"]
  \end{tikzcd}
\]
It is left as an exercise to check that \(\tilde \Phi_U\) is a diffeomorphism.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item If \(B = *\) then \(E \cong V\). Have
    \begin{align*}
      \tilde \Phi: f^*E &\to M \times V \\
      x &\mapsto (\tilde \pi(x), F(x))
    \end{align*}
    as a (global) trivialisation of \(f^*E\) over \(M\).
  \item As a variant, let \(M = B \times X\) with \(f: B \times X \to B\) the projection to first coordinate. Then \(f^*E\) is ``trivialised in the \(X\) direction'', i.e.\ \(f^*E \cong E \times X\) and \(\tilde \pi = \pi \times \id_X\).
  \item Suppose \(M = *\). Then \(f^*E\) is just a copy of the fibre \(V\) and \(F: V \embed E\) is an embedding as the fibre over \(f(M) \in B\).
  \end{enumerate}
\end{eg}

In general, \(f^*E\) may be determined by pulling back the transitions
\[
  f^* \psi_{\beta\alpha} = \psi_{\beta\alpha} \compose f: f^{-1}(U_\alpha \cap U_\beta) \to \GL(V).
\]
This gives an equivalent but more formal way to define pullbacks of bundles.

The above discussion applies equally well to pullbacks of principal \(G\)-bundles \(f^*P\), with obvious change of notations.

\subsection{Bundle morphism}

\begin{definition}[vector bundle morphism]\index{vector bundle!morphism}
  Let \(\pi: E \to B, \pi': E' \to B'\) be two vector bundles and \(f: B \to B'\) a smooth map. A smooth map \(F: E \to E'\) is a \emph{vector bundle morphism (covering \(f\))} if the diagram
  \[
    \begin{tikzcd}
      E \ar[r, "F"] \ar[d, "\pi"] & E' \ar[d, "\pi'"] \\
      B \ar[r, "f"] & B'
    \end{tikzcd}
  \]
  commutes and for all \(p \in B\), the restriction \(F_p = F|_{E_p}: E_p \to E'_{f(p)}\) is a linear map.
\end{definition}

It follows that if \(\Phi, \Phi'\) are local trivialisations of \(E\) and \(E'\) respectively over \(U \subseteq B, U' \subseteq B'\) with \(f(U) \subseteq U'\), then the local expression \(\hat F = \Phi' \compose F \compose \Phi^{-1}\) is given by
\[
  \hat F(b, v) = (f(v), h(b)(v))
\]
for all \(b \in U\) and \(h: U \to L(V, V')\) is a smooth map.

\begin{eg}\leavevmode
  \begin{enumerate}
  \item Suppose \(\varphi: M \to N\) is a smooth map then \(d \varphi: TM \to TN\) given by \(d\varphi_p\) for all \(p \in M\) is a bundle morphism.
  \item Given \(f: M \to B\) and \(\pi: E \to B\) a vector bundle, the pullback \(F: f^*E \to E\) is a bundle morphism.
  \item Let \(B' = B\) and \(f: B \to B\) a diffeomorphism. If for all \(p \in B\), \(F_p: E_p \to E_{f(p)}\) is a linear isomorphism then \(F\) is an \emph{vector bundle isomorphism}\index{vector bundle!isomorphism}. Furthermore if \(f = \id_B, E' = E, \pi' = \pi\) then we have the commutative diagram
    \[
      \begin{tikzcd}
        E \ar[r, "F"] \ar[dr, "\pi"] & E \ar[d, "\pi"] \\
        & B
      \end{tikzcd}
    \]
    In this case \(F\) is called an \emph{automorphism}\index{vector bundle automorphism} of \(E\) and denote it by \(F \in \aut(E)\).
  \item For example if \(E \cong V \times V\) then \(\aut(E) = C^\infty(V, \GL(V))\). If \(E\) has a \(G\)-structure then \(\aut_G(E) \subseteq \aut(E)\) is well-defined. Locally
    \[
      \hat F(b, v) = (v, h(b)(v))
    \]
    where \(h(v) \in G \subseteq \GL(V)\), whenever \(\hat F\) is with respect to local trivialisations \(\Phi\) from this \(G\)-structure. In mathematical physics, often write \(\aut_G(E) = \mathcal G\), the \emph{group of gauge transformations}. For example, \(G = U(1), SU(2), SO(3), SU(3)\).
  \end{enumerate}
\end{eg}

\section{Connections}

Let \(\pi: E \to B\) be a vector bundle and \(s: B \to E\) is a section. Locally
\begin{align*}
  \hat s: U &\to U \times V \\
  b &\mapsto (b, s(b))
\end{align*}
which is really, just a map to \(V\) so \(d\hat s_p: T_bU \to T_{s(b)}(V) \cong V\). On the other hand, the ordinary differential of \(s\) is a map \(ds_b: T_b B \to T_{(b, s(b))}E\). We would like \(T_{s(b)}E_b \cong E_b\) for some subspace of \(T_{s(b)}E\).

How to define differential of a section of a vector bundle so that it looks reasonable like a gradient

Some conventions throughout: let \(\dim B = n\) and \(U \subseteq B\) a coordinate neighbourhood that is simultaneously a trivialising neighbourhood for \(E\), with coodinates \(x^k\) where \(k = 1, \dots, n\). Let \(a = (a^j)_{j = 1}^m \in \R^m\) be coordinates on the fibres on \(E\). We use \(i, j = 1, \dots, m\) and \(k = 1, \dots, n\) and use summation convection for Roman indices (but not Greek indices).

Let \(\Phi_U: \pi^{-1}(U) \to U \times \R^m\) be a local trivialisation. Let \(T_p\) be the span of \(\frac{\partial  }{\partial x^k}, \frac{\partial  }{\partial a^j}\). For \(p \in E, \pi(p) = b\), Let \(\pi^{-1}(b) = E_b \subseteq E\) is a submanifold.
\[
  T_pE_b = \ker (d\pi_p)
\]
which is the span of \(\frac{\partial  }{\partial a^j}\).

\begin{definition}
  The \emph{vertical subspace} at \(p \in E\) is
  \[
    Tv_pE = \ker(d\pi_p).
  \]

  A subspace \(S_p \subseteq T_pE\) is a  \emph{horizontal subspace} if
  \begin{align*}
    S_p \cap Tv_p E &= 0 \\
    S_p \oplus Tv_p E &= T_pE
  \end{align*}
\end{definition}

Then \(\dim S_p = \dim B\).

How to choose a horizontal subspace? All \(n\) dimensional subspace of \(T_pE \cong \R^{m + n}\) is \(\bigcap_{i = 1}^m \ker \theta^i\) for some linearly independent \(\theta^1, \dots, \theta^m \in (\R^{m + n})^* \cong T_p^*E\) where
\[
  \theta^i = f_k^i \mathrm d x^k + g_j^i \mathrm d a_j
\]
where \(f_k^i, g_j^i \in \R\). A subspace \(C = B^k \frac{\partial  }{\partial x^k} + C^j \frac{\partial  }{\partial a^j} \in T_p E\) is vertical if and only if \(B^k = 0\) for all \(k\). Thus must have
\[
  \theta_p^i(C_j \frac{\partial  }{\partial a^j}
\]
not all \(0\) for \(i = 1, \dots, n\), i.e.\ \(g^i_j C^j = 0\) for all \(i\), which implies \(C^j = 0\) for all \(j\). Hence the \(m \times m\) matrix \((g_j^i)\) is invertible. Let its inverse be \((h_j^i)\). Put
\[
  \tilde \theta_p^i := h_j^i \theta_p^j = \mathrm d a^j + e^i_k \mathrm d x^k
\]
which determines the same subspace \(S_p \subseteq T_pE\), where
\[
  e_k^i = e_k^i(p) = e_k^i(x, a) \in C^\infty(U \times \R^n).
\]

\begin{proposition}
  Every given field of horizontal subspace \(S_p, p \in E\) is locally expressed as
  \[
    S_p = \bigcap_{i = 1}^m \ker \theta_p^i
  \]
  where
  \[
    \theta_p^i = \mathrm d a^i + e_k^i(x, a) \mathrm dx^k
  \]
  for some unique functions \(e_k^i\) on \(U \times \R^m\).

  We say \(S = S_p\) is smooth if all \(e_k^i\) are smooth.
\end{proposition}

\begin{definition}[connection]\index{connection}
  \(S = S_p\) a field of horizontal subspaces is a \emph{connection} of \(E\) if all \(e_k^i\)'s are linear in \(a\). Write
  \[
    e_k^i(x, a) = \Gamma_{jk}^i (x) a^j
  \]
  where \(\Gamma_{jk}^i \in C^\infty(U)\) are the coefficients of this connection in a local trivialisation.
\end{definition}

\[
  \theta^i = \mathrm d a^i + \Gamma_{jk}^i(x) a^j \mathrm dx^k
  = \mathrm d a^i + A^i_ja^j
\]
where \(A^i_j \in \Omega^1(U)\).

The transformation law for \(A^i_j\): if \(U'\) is another trivialisation neighbourhood with \(U \cap U' \neq \emptyset\) and \(\Psi = (\Psi^{i'}_i)_{m \times m}\) is the transition function from \(\Phi_U\) to \(\Phi_{U'}\), and \(\Psi^{-1} = (\Psi^i_{i'})_{m \times m}\) the transition function fro \(\Phi_{U'}\) to \(\Phi_U\). Note that
\[
  \Psi_{i'}^i \Psi_j^{i'} = \delta_j^i.
\]
Suppose \(a^{i'} = \Psi_i^{i'} a^i\), then
\[
  \mathrm d a^{i'} = (d \Psi_i^{i'}) a^i + \Psi_i^{i'} da^i.
\]
Suppose
\begin{align*}
  \theta^{i'} &= d a^{i'} + A_{j'}^{i'} a^{j'} \\
  \theta^i &= da^i + A_j^i a^j
\end{align*}
then rewrite
\[
  \theta^{i'} = (d \Psi_i^{i'}) a^i + \Psi_i^{i'} da^i + A_{j'}^{i'} a^{j'}
\]
Compare the coefficient of \(da^i\), must have
\[
  \theta^i = \Psi_{i'}^i \theta^{i'}
\]
so
\[
  \theta^i = da^i + (\Psi_{i'}^i d\Psi_j^{i'} + \Psi_{i'}^i A_{j'}^{i'} \Psi_j^{j'}) a^j
\]
so the transformation law is
\[
  A_j^i = \Psi_{i'}^i A_{j'}^{i'} \Psi_j^{j'} + \Psi_{j'}^i d\Psi_j^{i'}.
\]
Use \(A^\Phi\) to denote the matrix \((A_j^i)\), have \(A^{\Phi'} = A^{\Psi\Phi} = (A_{j'}^{i'})\). Then the transformation law is
% \[
%   A^\Phi = \Psi A^{\Psi\Phi} \Psi^{-1} + \Psi d\Psi^{-1}
% \]
% or equally
\[
  A^{\Psi\Phi} = \Psi A^\Phi \Psi^{-1} - (d\Psi) \Psi^{-1}.
\]
Noting that
\[
  (d\Psi)\Psi^{-1} + \Psi d(\Psi^{-1}) = 0
\]
so equally
\[
  A^\Psi = \Psi^{-1}A^{\Psi\Phi} \Psi + (d\Psi)\Psi^{-1}.
\]

\begin{theorem}
  Every choice of local matrices \((A_j^i)\) of \(1\)-forms satifying * assigned to local trivialisations defines a connection on \(E\).
\end{theorem}

Recall the transformation law for the connection matrices
\[
  A^{\Psi\Phi} = \Psi A^\Phi \psi^{-1} - (d\Psi) \Psi^{-1}
\]
where \(\Psi\) is the transition function from local trivialisation \(\Phi\) to \(\Phi'\) with \(\Phi = \Phi' \compose \Phi^{-1}\). Write \(A^\Phi = (A^i_j)_{i,j = 1, \dots, m}\) where \(m\) is rank of \(E\),
\[
  A^i_j = \Gamma^i_{jk}(x) \mathrm d x^k \in \Omega^1(U).
\]
Similarly \(A^{\Psi\Phi} = (A^{i'}_{j'})\). The \((A^i_j)\)'s do \emph{not} patch together over trivialising neighbourhoods \(U \subseteq B\) to give a global matrix-valued \(1\)-form, essentialy because of the \((d\Psi) \Psi^{-1}\) correction term in the transformation law.

Let \(\Phi_\alpha, \Phi_\beta: \pi^{-1}(U) \to U \times V\) be two trivialising neighbourhoods over \(U\). If \(G_\alpha \in \End(V)\) considered in the \(\Phi_\alpha\) trivialisation then with respect to \(\Phi_\beta\), \(G_\alpha\) becomes
\[
  G_\beta = \Psi_{\beta\alpha} G_\alpha \Psi_{\alpha\beta},
\]
note that there is no summation here! This defines a linear action of \(\GL(V)\) on \(\End(V)\). Thus we can apply the Steenrod construction to build a vector bundle \(\End(E)\) using \(U \times \End(V)\) and the above formula for the transitions. This is the \emph{endomorphism bundle}\index{endomorphism} of \(E\). This is the bundle associated to \(E\).

\begin{remark}
  We may also define subbundle \(\GL(E) \subseteq \End(V)\) with typical fibre \(\GL(V) \subseteq \End(V)\). \(\GL(E)\) is \emph{not} a principal bundle. For example it always has a global section
  \begin{align*}
    B &\to \GL(E) \\
    b &\mapsto \id_V
  \end{align*}
  Sections of \(\GL(E)\) are precisely \(\aut(E)\). Coincidentally this also provides a practical counterexample to the statement that ``every vector bundle with transition functions in a group is a principal bundle''.
\end{remark}

Similarly to \(\End(E)\) we may build a vector bundle with typical fibre
\[
  \Lambda^r(\R^n)^* \otimes V \cong \{f: \underbrace{\R^n \times \dots \times \R^n}_{r \text{ times}} \to V \text{ multilinear and antisymmetric}\}
\]
(where the isomorphism comes from the fact in linear algebra that \((\R^n)^* \otimes V \cong \{\text{linear maps } \R^n \to V\}\) and so on), where \(n = \dim B\). Use the action induced by the Jacobi matrices for local coordinate transformation on \(B\) and use \(\Psi_{\alpha\beta}\)'s on the \(V\) factor.

\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    vector bundle & typical fibre & transition functions \\ \hline
    \(E\) & \(V\) & \(v \mapsto \Psi_{\beta\alpha}v\) \\ \hline
    \(\End(E)\) & \(\End(V)\) & \(G \mapsto \Psi_{\beta\alpha} G \Psi_{\alpha\beta}\) \\ \hline
    \(T^*B \otimes E\) & \(L(\R^n, V) \cong (\R^n)^* \otimes V\) & \(v_k \mathrm dx^k \mapsto (\Phi_{\beta\alpha} v_k) \frac{\partial x^k}{\partial x^{k'}} \mathrm d x^{k'}\) \\ \hline
    \(\Lambda^r(T^*B) \otimes E\) & \(\Lambda^r(\R^n)^* \otimes V\) & \(v_K \mathrm d x^K \mapsto (\Phi_{\beta\alpha}v_K) \frac{D x^K}{D x^{k'}} \mathrm dx^{K'}\) \\ \hline
    \(T^*B \otimes \End E\) & \((\R^n)^* \otimes \End V\) & \(G_k \mathrm dx^k \mapsto (\Psi_{\beta\alpha} G_k \Psi_{\alpha\beta}) \frac{\partial x^k}{\partial x^{k'}} \mathrm d x^{k'}\) \\ \hline
    \(\Lambda^rT^*B \otimes \End E\) & \(\Lambda^r(\R^n)^* \otimes \End V\) &  \\ \hline
  \end{tabular}
\end{table}

whwere we multiply vectors and matrices in \(\Lambda^r V \otimes E\) and \(\Lambda^r V \otimes \End V\) using the wedge product of forms.

(The good news is we mostly use \(r = 1, 2\))

Connections are \emph{not} sections of \(T^*B \otimes \End E\), but if \(A\) and \(\tilde A\) are two connections then \(A - \tilde A\) \emph{is} a valid section of \(T^*B \otimes \End E\). Thus the space of all connections \(A\) on a given vector bundle \(E\) is an \emph{affine space} modeled on  section of \(T^*B \otimes \End E\), written \(\Omega^1_B(\End E)\). (this means there is no canonical zero section).

\begin{notation}
  Use \(\Gamma(E)\) to denote all sections of \(E\) and \(\Omega^r_B(E), \Omega^r_B(\End E)\) to denote sections of \(\Lambda^r T^*B \otimes E\) and \(\Lambda^r T^*B \otimes \End E\). In particular \(\Omega^0_B(E) = \Gamma(E)\).
\end{notation}

Now we are ready to define calculus on vector bundles.

\begin{definition}[covariant derivative]\index{covariant derivative}
  A \emph{covariant derivative} on a real vector bundle \(E\) over \(B\) is a \(\R\)-linear map \(\nabla^E: \Gamma(E) \to \Omega^1_B(E)\) satisfying the Leibniz rule
  \[
    \nabla^E(fs) = \mathrm df \otimes s + f \nabla^E s
  \]
  for all \(s \in \Gamma(E), f \in C^\infty(B)\).
\end{definition}

\begin{eg}
  Let \(A\) be a connection on \(E\). Have in any local trivialisation \(A = (A_j^i)\) where \(A_j^i \in \Omega^1(U)\). Define an map \(\mathrm d_A\) which is locally given by
  \[
    \mathrm d_A s|_U = (\mathrm ds + As)|_U = (\mathrm ds^i + A_j^i s^j)_{i = 1, \dots, m}
  \]
  where \(m\) is rank of \(E\). To check this is well-defined, if \(U\) is also a coordinate neighbourhood in \(B\) then
  \[
    (\mathrm d_A s)^i = \left( \frac{\partial s^i}{\partial x^k} + \Gamma_{jk}^i(x) s^j \right) \mathrm dx^k.
  \]
  Let \(\Phi'\) be another local trivialisation over \(U\). Then
  \begin{align*}
    s &= \Psi s' \\
    A &= \Psi A' \Psi^{-1} - (d\Psi) \Psi^{-1}
  \end{align*}
  so
  \begin{align*}
    \mathrm d_A(s)
    &= \mathrm d s + As \\
    &= \mathrm d(\Psi s') + (\Psi A \Psi^{-1} - (d \Psi) \Psi^{-1}) \Psi s' \\
    &= \Psi \mathrm ds' + (d\Psi) s' + \Psi A' s' - (d\Psi) s' \\
    &= \Psi(\mathrm d s' + A's') \\
    &= \Psi(\mathrm d_A s)'
  \end{align*}
  which is the correction transformation law for \(\Omega^1_B(E)\).
\end{eg}

\begin{theorem}
  Every covariant derivative \(\nabla^E\) arises as \(\nabla^E = d_A\) for some connection \(A\) on \(E\).
\end{theorem}

Recall that
\[
  d_AS = ds + AS
\]
where RHS only makes sense with a choice of local trivialisation!

\begin{proof}
  Claim every \(\nabla^E\) is a local operator. i.e.\ for all \(U \subseteq B\) open, if \(s_1|_U = s_2|_U\) then \(\nabla^E s_1|_U = \nabla^E s_2|_U\). (remark by writer of note: essentially partition of unity subject to \(\{U, B \setminus \cl U_0\))
  Indeed for all \(b \in U\) let
  \[
    b \in U_0 \subseteq \cl U_0 \subseteq U
  \]
  and let \(\alpha \in C^\infty(B)\) such that \(0 \leq \alpha \leq 1, \alpha|_{B \setminus U} = 0\). Then
  \[
    0 = \nabla^E (\alpha(s_1 - s_2))
    = d\alpha \otimes (s_1 - s_2)
    + \alpha \nabla^E(s_1 - s_2)
  \]
  At \(b\), \(d\alpha_b = 0, \alpha(b) = 1\) whence
  \[
    (\nabla^E s_1)(b) = (\nabla^E s_2)(b)
  \]
  so it suffices to work in trivialising neighbourhoods. Let \(\V s = (s^1, \dots, s^m) = s^i \V e_i\) where \(\V e_i\) is the standard basis of \(\R^m\) and \(s^i \in C^\infty(U)\). Put
  \[
    \Gamma_{jk}^i = \left[(\nabla^E \V e_j) \frac{\partial  }{\partial x^k} \right]^i
  \]
  where we assumed that \(U\) is also a coordinate neighbourhood in \(B\). \(\Gamma_{jk}^i \in C^\infty(U)\). Thus
  \[
    \nabla^E \V s = \nabla^E (s^i \V e_i)
    = (ds^i + s^j \Gamma^i_{jk}(x) dx^k) \otimes \V e_i
    = d_As
  \]
  Then the previous example verifies that \(A_j^i = \Gamma_{jk}^i dx^k\) have the required transformation law.
\end{proof}

\begin{definition}[covariantly constant]\index{covariantly constant}
  A (local) section \(s: U \to E\) is \emph{covariantly constant} with respect to connection \(A\) if \(d_As = 0\).
\end{definition}

This is geometer's constant vector function.

\begin{proposition}
  \((d_As)(x) = 0\) if and only if \((ds)x(TxB) \subseteq T_{s(x)}E\) is a horizontal subspace \((ds_x (T_xB) = S_{s(x)}\) associated with \(A\).
\end{proposition}

\begin{proof}
  Exercise.
\end{proof}

We can extend \(d_A\) as a \(\R\)-linear map \(d_A: \Omega_B^r(E) \to \Omega_B^{r + 1}(E)\) for \(r = 0, 1, \dots\) by requiring
\[
  d_A(\sigma \w \omega) = (d_A\sigma) \w \omega + (-1)^{\deg \sigma} \sigma \w d\omega
\]
for all \(\sigma \in \Omega_B^q(E), \omega \in \Omega_B^p(B)\). Locally
\[
  d_A(s_I dx^I) = (d_A s_I) \w dx^I = d(s_i dx^I) + (A \w s^I) dx^I,
\]
i.e.\
\[
  d_A\sigma = d\sigma + A \w \sigma.
\]
Again, RHS only makes sense with a choice of local trivialisation. Can futher extend \(d_A\) to
\[
  d_A: \Omega_B^r(\End E) \to \Omega_B^{r + 1}(\End E)
\]
via
\[
  (d_AC)s = d_A(Cs) - Cd_As
\]
for all \(C \in \Gamma(\End E),  s \in \Gamma(E)\) (this is really just product rule rearranged). Also
\[
  (d_A\mu) \omega \sigma = d_A(\mu \w \sigma) - (-1)^{\deg \mu} \mu \w d_A\sigma
\]
for \(\mu \in \Omega_B^p(\End E), \sigma \in \Omega_B^r(E)\). Finally
\[
  d_A(\mu_1 \w \mu_2) = (d_A\mu-1) \w \mu_2 + (-1)^{\deg \mu_1} \mu_1 \w d_A \mu
\]
for \(\mu_1, \mu_2 \in \Omega_B^*(\End E)\).

\begin{eg}
  For \(\mu \in \Omega_B^2(\End E)\), the above theory implies in that in any local trivialisation,
  \[
    d_A\mu = d\mu + A \w \mu - \mu \w A.
  \]
\end{eg}

\subsection{Curvature}

We may repeatedly apply covariant derivative \(d_A\) to get a chain
\[
  \Gamma(E) = \Omega_B^0(E) \xrightarrow{d_A} \Omega_B^1(E) \xrightarrow{d_A} \dots \xrightarrow{d_A} \Omega_B^n(E) \xrightarrow{d_A} 0.
\]
Unfortunately in general \(d_A \compose d_A \neq 0\) so we don't have a cohomology. However in a local trivilisation, let \(s \in \Omega_B^r(E)\), have
\begin{align*}
  d_A d_As
  &= d(ds + A \w s) + A \w (ds + A \w s) \\
  &= dA \w s - A \w ds + A \w ds + A \w A \w s \\
  &= (d A + A \w A) \w s
\end{align*}
so \(d_Ad_A\) is multiplication by a \(2\)-form. The expression is a pointwise (i.e.\ algebraic) expression: if \(s_1(b) = s_2(b)\) then
\[
  (d_A d_A s_1)_b = (d_A d_A s_2)_b.
\]

\begin{note}
  One may wonder why \(A \w A\) does not vanish in the expression. In fact it is matrix valued:
  \[
    (A \w A)_j^i
    = \Gamma_{pk}^i dx^k \w \Gamma_{j\ell}^p dx^\ell
    = \Gamma_{pk}^i \Gamma_{j\ell}^p dx^k \w dx^\ell
    \neq 0
  \]
  which is nonvanishing in general unless \(E\) has rank \(1\). In summary, matrix multiplicaiton is noncommutative.
\end{note}

\begin{definition}[curvature]\index{curvature}
  Given a connection \(A\), the \(2\)-form
  \[
    F(A) = dA + A \w A \in \Omega_B^2(\End E)
  \]
  is the \emph{curvature} of \(A\).
\end{definition}

Note that \(F(A)\) is well-defined (i.e.\ independent of local trivialisation) as \(d_Ad_A\) is so.

Locally \(FA = F(A)_{j, k\ell}^i dx^k \w dx^\ell\) where \(\{F(A)_{j, k\ell}^i\}\) is a function of \(\{\Gamma_{jk}^i, \frac{\partial \Gamma_{jk}^i}{\partial x_ell}\}\).

\begin{definition}[flat]\index{connection!flat}\index{vector bundle!flat}
  A connection is \emph{flat} if \(F(A) = 0\).

  A vector bundle \(E\) is \emph{flat} if made a choice of flat connection.
\end{definition}

\begin{eg}
  Consider the product bundle \(E = B \times \R^m\). Then
  \[
    d_A = d: C^\infty(B, \R^m) \to \Omega^1(B) \otimes \R^m
  \]
  is a \emph{trivial} product connection. It is flat.

  The converse is true only locally and only if connection is flat.
\end{eg}

\begin{theorem}[2nd Bianchi identity]\index{2nd Bianchi identity}
  \[
    d_AF(A) = 0
  \]
  for every connection \(A\) on vector bundle \(E\).
\end{theorem}

\begin{proof}
  Let \(s \in \Gamma(E)\). Then
  \[
    d_A(F(A)s) = d_A(d_Ad_A)s = (d_Ad_A)d_As = F(A) \w d_As.
  \]
  Bu LHS may be rewritten as
  \[
    d_A(F(A))s + F(A) \w d_As.
  \]
  Substitute and cancel to get the result.
\end{proof}

\section{Riemannian geometry}

\begin{definition}
  A \emph{Riemannian metric} \(g\) on \(M\) is a field of positive-definite symmetric bilinear forms
  \[
    g_p : T_pM \times T_pM \to \R
  \]
  defined for all \(p \in M\) and smooth in \(p\).
\end{definition}

\begin{definition}[Riemannian manifold]\index{Riemannian manifold}
  A \emph{Riemannian manifold} is a manifold endowed with a Riemannian metric.
\end{definition}

\begin{remark}
  Smoothness in \(p\) means that for all \(X, Y \in V(M)\) have \(g(X, Y) \in C^\infty(M)\). Equivalently, in each coordinate neighbourhood \(U\) with coordinates \(x^i\) have
  \[
    g_{ij} = g(\frac{\partial  }{\partial x^i}, \frac{\partial  }{\partial x^j}) \in C^\infty(U).
  \]
  We thus obtain the local expression of \(g\)
  \[
    g_{ij} dx^idx^j.
  \]
  Technically it should be \(g_{ij} dx^i \otimes dx^j\) but we omit the tensor symbol. This means that suppose \(X = X^i \frac{\partial  }{\partial x^i}, Y = Y^i \frac{\partial  }{\partial x^i}\) then
  \[
    g(X, Y) = g_{ij} X^iY^j.
  \]
\end{remark}

Formally \(g \in \Gamma(T^*M \otimes T^*M)\).

\begin{eg}
  This is compatible with the more classical definition of Riemannian metric in differential geometry of curves and surfaces. Given \(r = r(u, v): \R^2_{u, v} \to \R^3\), the first fundamental form
  \[
    E du^2 + 2F dudv + G dv^2
  \]
  is a Riemannian metric with \(g_{11} = E, g_{12} = g_{21} = F, g_{22} = G\).
\end{eg}

\begin{theorem}
  Every manifold admits a Riemannian metric.
\end{theorem}

\begin{proof}
  Apply example sheet 3 question 2 (every vector bundle can be given a smooth inner product) to \(TM\).
\end{proof}

The definition of a pullback \(F^*\) for smooth \(F: M \to B\) is valid for bilinear forms of \(TN\). If \(g_N\) is a metric on \(N\) then \(F^*g_N\) is a symmetric, bilinear smooth and non-negative definite on fibres of \(TM\).

If also \(dF_x\) are injective for all \(x \in M\) then \(F^*g_N\) is positive-definite on \(TM\) and is a valid Riemannian metric. For example, when \(M\) is a immersed submanifold or \(F\) is a diffeomorphism.

This gives us an alternative way to prove the theorem by embedding in Euclidean space by Whitney and pullback the Euclidean metric.

\begin{definition}[connection]\index{connection}
  A \emph{connection on a manifiold \(M\)} is a connection on \(TM\).
\end{definition}

Recall that transition functions for \(TM\) are given by the Jacobian
\[
  \psi = (\psi^i_{i'}) = \left( \frac{\partial x^i}{\partial x^{i'}} \right)
\]
The coefficients \(\Gamma_{jk}^i\) of a connection on \(M\) are sometimes called \emph{Christoffel symbols}\index{Christoffel symbols}. Recall the transformation law for connection %forms matrices \((A_j^i) = (\Gamma_{jk}^i dx^k)\)
\[
  \Gamma^i_{jk} = \Gamma^{i'}_{j'k'} \psi^i_{i'} \psi^{j'}_j \frac{\partial x^{k'}}{\partial x^k} + \psi^i_{i'} \frac{\partial \psi^{i'}_j}{\partial x^k}
\]
When \(E = TM\) this simplifies to
\[
  \Gamma^i_{jk} = \Gamma^{i'}_{j'k'} \frac{\partial x^i}{\partial x^{i'}} \frac{\partial x^{j'}}{\partial x^j} \frac{\partial x^{k'}}{\partial x^k} + \frac{\partial x^i}{\partial x^{i'}} \frac{\partial^2 x^{i'}}{\partial x^j \partial x^k}
\]
Note that in this case the object \(\Gamma^i_{kj}\) obtained by switching \(j\) and \(k\) makes sense as they live in the same space. It obeys the same transformation law so they also define a connection.

The difference \(T^i_{jk} = \Gamma^i_{jk} - \Gamma^i_{kj}\) is the \emph{torsion}\index{torsion} of a connection on \(M\). \(T = (T^i_{jk}) \in \Omega^1_M(\End TM)\). Locally \(T = T^i_{jk} dx^k\). Moerover given \(X, Y \in V(M)\),
\[
  T(X, Y) = (T^i_{jk} X^j Y^k \frac{\partial  }{\partial x^i}) \in V(M).
\]
Then \(T(X, Y) = -T(Y, X)\) so \(T \in \Omega^2_M(TM)\)

\begin{definition}[symmetric connection]\index{connection!symmetric}
  A connection on a manifold \(M\) is \emph{symmetric} if the torsion vanishes, i.e.
  \[
    \Gamma^i_{jk} = \Gamma^i_{kj}
  \]
  in every local coordinates.
\end{definition}

Denote the covariant derivative on \(M\)
\[
  D: \Omega_M^0(TM) = V(M) \to \Omega_M^1(TM).
\]
Denote by \(D_XY\), where \(X, Y \in V(M)\) the evaluation of \(DY \in \Omega^1_M(TM)\) on \(X\). Thus \(D_XY \in V(M)\). This is an \(\R\)-linear map.

In local coordinates,
\[
  (D_XY)^i \p_i = (X^j\p_j Y^i - \Gamma^i_{jk} Y^jX^k) \p_i
\]
Consequently we obtain

\begin{proposition}
  A connection \(D\) on \(M\) is symmetric if and only if
  \[
    D_XY - D_YX = [X, Y]
  \]
  for all \(X, Y \in V(M)\).
\end{proposition}

\begin{theorem}[Levi-Civita connection]\index{Levi-Civita connection}
  \label{thm:Levi-Civita}
  On each Riemannian manifold \((M, g)\) there is a unique connection \(D\) such that
  \begin{enumerate}
  \item for every \(X, Y, Z \in V(M)\),
    \[
      Zg(X, Y) = g(D_ZX, Y) + g(X, D_ZY).
    \]
  \item \(D\) is symmetric.
  \end{enumerate}

  \(D\) is called \emph{Levi-Civita connection} of \(g\).
\end{theorem}

Recall that given \(X \in V(M)\), \(D_X: V(M) \to V(M)\) is a covariant derivative if and only if
\begin{enumerate}
\item \(\R\)-linearity in \(Y\): \(D_X(\lambda Y) = \lambda D_XY\) for all \(\lambda \in \R, Y \in V(M)\),
\item Leibniz rule: \(D_X(hY) = (Xh) \cdot Y + hD_XY\) for all \(h \in C^\infty(M)\),
\item \(C^\infty(M)\)-linearity in \(X\): \(D_{fX}Y = fD_XY\) for all \(f \in C^\infty(M)\).
\end{enumerate}

\begin{proof}[Proof of \Cref{thm:Levi-Civita}]
  We do uniqueness first. In a coordinate neighbourhood
  \[
    D \p_i = \Gamma_{ik}^p \p_p dx^k.
  \]
  For condition 1 in the statement of the theorem, let \(X = \p_i, Y = \p_j, Z = \p_k\) so that \(g(X, Y) = g_{ij}\), so we obtain the first equation
  \begin{align*}
    \p_k g_{ij} &= \Gamma_{ij}^p g_{pj} + \Gamma_{jk}^p g_{ip} \\
    \p_j g_{ki} &= \Gamma_{kj}^p g_{pi} + \Gamma_{ij}^p g_{kp} \\
    \p_i g_{jk} &= \Gamma_{ji}^p g_{pk} + \Gamma_{ki}^p g_{jp}
  \end{align*}
  the next two lines are similarly obtained by cyclic permutation on \(i, j, k\).

  Define \((g^{iq}) = (g_{iq})^{-1}\), the inverse matrix. Use the fact that \(g_{iq}\) is symmetric,
  \[
    \Gamma_{jk}^p g_{pq} g^{iq} = \Gamma_{jk}^i.
  \]
  Summing equations \(1 + 2 - 3\) gives
  \[
    \p_k g_{ij} + \p_j g_{ki} - \p_i g_{jk}
    = 2\Gamma_{jk}^p g_{ip}
  \]
  which is the same as
  \[
    \Gamma_{jk}^p g_{qp} = \frac{1}{2} (\p_k g_{qj} + \p_j g_{kq} - \p_q g_{jk}).
  \]
  Multiply by \(g^{iq}\) to get
  \[
    \Gamma_{jk}^i = \frac{1}{2} g^{iq}(\p_k g_{qj} + \p_j g_{kq} - \p_q g_{jk})
  \]
  which is to say, there is at most one way to define the Christoffel symbols.

  \begin{ex}
    Show that the equation has a coordinate-free formulation
    \begin{align*}
      g(D_XY, Z) &= \frac{1}{2}(X_g(Y, Z) + Y_g(Z, X) - Zg(X, Y) \\
      &\quad - g(Y, [X, Z]) - g(Z, [Y, X]) + g(X, [Y, Z])).
    \end{align*}
  \end{ex}

  To check the requirement for covariant derivative, 1 is clear from the coordinate-free formula. We omit the verification for 2 and 3 with the following checkpoints:
  \begin{enumerate}
  \item 3: Let \(f \in C^\infty(M)\). Recall
    \[
      [fX, Z] = (fX)Z - Z(fX) = f[X, Z] - (Zf)X
    \]
    so
    \begin{align*}
      g(D_{fX}Y, Z)
      &= \frac{1}{2}(fX_g(Y, Z) + Y(fg(Z, X)) - Z(fg(X, Y)) \\
      &\quad - f(g(Y, [X, Z]) + g(Z, [Y, X]) - g(X, [Z, Y])) \\
      &\quad + (Zf)g(X, Y) - (Yf)g(Z, X) \\
      &\dots \\
      &= g(fD_XY, Z)
    \end{align*}
    then do some cancellation. We are also using
    \[
      Y(fh) = (Yf) \cdot h + f \cdot Yh.
    \]
  \item 2: let \(h \in C^\infty(M)\),
    \begin{align*}
      g(D_X(hY), Z)
      &= \frac{1}{2}(X(h g(Y, Z)) + hY(g(Z, X)) - Z(hg(X, Y)) - hg(Y, [X, Z]) - g(Z, [hY, X]) + g(X, [Z, hY]) \\
      &= \frac{1}{2}((Xh)g(Y, Z) + h Xg(Y, Z) + hY(g(Z, X)) - (Zh) g(X, Y) - hZ g(X, Y) - hg(Y, [X, Z]) + (Xh) g(Z, [Y, X]) + (Zh) g(X, Y) + hg(X, [Z, Y]) \\
      &= (Xh) g(Y, Z) + hg(D_XY, Z)
    \end{align*}
    for all \(Z\). Thus
    \[
      D_X(h, Y) = (Xh)Y + hD_XY.
    \]
  \end{enumerate}
  Thus \(D\) is a well-define connection. For statment 1 in theorem, we can trace deduction of \(\Gamma_{jk}^i\) backwards.
\end{proof}

\subsection{Geodesics}

Let \(\gamma\) be a curve in \(U\), a coordinate neighbourhood of \(M\). Let \(\pi: E \to M\) be a vector bundle equipped with a connection \(A\), \(A = (\Gamma_{jk}^i)\) on \(U\). Then a \emph{lift} of \(\gamma\) to \(E\) is \(\gamma_E\) such that \(\pi \compose \gamma_E = \gamma\). If \(\gamma(t) = (x^k(t))\) in local coordinates, then
\[
  \gamma_E(t) = (x^k(t), a^i(t))
\]
in \(U \times V = \pi^{-1}(U)\). A \emph{horizontal lift} means that
\[
  \dot \gamma_E(t) \in S_{\gamma_E(t)}
\]
for all \(t\) where \(S\) denotes the horizontal subspace with respect to \(A\). In other words,
\[
  \theta^i(\dot \gamma_E(t)) = 0
\]
for \(i = 1, \dots, m\) where \(m\) is the rank of \(E\). Expand out,
\[
  (da^i + \Gamma_{jk}^i a^j dx^k) (\dot x^k(t) \frac{\partial  }{\partial x^k} + \dot a^j(t) \frac{\partial  }{\partial a^j}) = 0.
\]
Simplify to get
\[
  \dot a^i + \Gamma_{jk}^i(x) a^j \dot x^k = 0.
\]
This is a system of \(1\)st order linear ODEs so by basic results in ODE theorey, it is solvable on ant \(I \subseteq \R\) and is uniquely determined by \(a^i(0)\). Thus horizontal lift \emph{always exists} from each \(a \in E\).

Misses a lecture on 17/11/18

Fix \(p \in M\). If \(\gamma(t, a) = \gamma_p(t, a)\) is a geodesic, \(\lambda \in \R\) then
\begin{align*}
  \frac{d}{dt} \gamma(\lambda t, a) &= \lambda \dot \gamma(\lambda t, a) \\
  \frac{d^2}{dt^2} \gamma(\lambda t, a) &= \lambda^2 \ddot \gamma(\lambda t, a)
\end{align*}
so
\[
  \gamma(\lambda t, a) = \gamma(t, \lambda a).
\]
Furthermore
\begin{enumerate}
\item for all \(a \in T_pM\), there exists \(\varepsilon = \varepsilon_a > 0\) such that
  \[
    \gamma(s, a) = \gamma(1, sa)
  \]
  exists for all \(|s| < \varepsilon\).
\item from theory of ODEs, \(\varepsilon_a\) may be chosen continuous in \(a\). For \(|a|_g \leq \varepsilon_1\), have \(\varepsilon_a \geq \varepsilon_2 > 0\). We have \(|a|_g < \varepsilon = \varepsilon_1 \varepsilon_2\) then \(\gamma(1, a)\) is defined.
\end{enumerate}

\begin{definition}[exponential map]\index{exponential map}
  Let \((M, g)\) be a Riemannian manifold and \(p \in M\). The \emph{exponential map} at \(p\) is
  \begin{align*}
    \exp_p: T_m M &\to M \\
    a &\mapsto \gamma_p(1, a)
  \end{align*}
\end{definition}
Thus for some \(\varepsilon > 0\) sufficiently small, \(\exp_p: \text{Ball}_g(0, \varepsilon) \to M\) is a well-defined smooth map.

\begin{proposition}
  \[
    (d \exp_p)_0 = \id_{T_pM}
  \]
  by noting \(T_0(T_pM) \cong T_pM\).
\end{proposition}

\begin{proof}
  One approach is to Taylor expand
  \[
    \gamma(t, a) = p + at + c_2 t^2 + \dots
  \]
  and then substitute into geodesic ODE to get
  \[
    c_2^i = \frac{1}{2} \Gamma_{jk}^i (\phi) a^ja^k.
  \]
  Then do some hands-on analysis.

  Another approach is to note \(\exp_p(0) = p\). For \(|a|_g < \varepsilon\), \(\gamma_p(t, a) = \gamma_p(1, ta)\) for \(-1 \leq t \leq 1\). Then
  \begin{align*}
    (d \exp_p)_0 a
    &= \frac{d}{dt} \exp_p(t a) \Big|_t = 0 \\
    &= \frac{d}{dt} \gamma_p(1, ta) \Big|_{t = 0}
      = \frac{d}{dt} \gamma_p (t, a) \Big|_{t = 0} \\
    &= \dot \gamma_p(t, a) \Big|_{t = 0} \\
    &= a
  \end{align*}
\end{proof}

\begin{corollary}
  \(\exp_p: \text{Ball}_g(0, r) \to U\) is a diffeomorphism onto its image \(U\) for some \(r > 0\).
\end{corollary}

\begin{proof}
  Inverse mapping theorem.
\end{proof}

This means that \((\exp_p)^{-1}\) is a hcart around \(p \in M\). The respective local coordinates are the \emph{normal coordinates}\index{normal coordinate}, aka \emph{geodesic coordinates}\index{geodesic coordinate} at \(p\).

For exmaple in geodesic coordinates
\[
  \exp_p^{-1} (\gamma_p(t, a)) = ta
\]
for \(|t|\) sufficiently small.

The \emph{geodesic polars} \((T_pM, g(p)) \cong (\R^n, \text{Euclidean})\). Suppose \((0, \varepsilon) \times S^{n - 1}\) is included in the domain of \(\exp_p\). Then can define a map
\begin{align*}
  f: (0, \varepsilon) \times S^{n - 1} &\to M \\
  (r, v) &\mapsto \exp_p(r v)
\end{align*}
Let \(\Sigma_r\) be the image under \(f\) of \(\{r\} \times S^{n - 1}\), then \(f\) defines an immersion (embed?) into \(M\). This is a \emph{geodesic sphere} around \(p\).

\begin{theorem}[Gauss lemma]\index{Gauss lemma}
  \(\gamma_p(t, a)\) meets \(\Sigma_r\) orthogonally for all \(0 < r < \varepsilon\). Thus in geodesic polars,
  \[
    g = dr^3 + h(r, v)
  \]
  where \(g = g|_{\Sigma_r}\).
\end{theorem}

So we may write \(g\) as
\[
  \begin{pmatrix}
    dr^2 & 0 & \dots & 0 \\
    0 \\
    \vdots & & h(r, v) \\
    0 
  \end{pmatrix}
\]

\begin{proof}
  Choose any \(X \in V(S^{n - 1})\). \(S^{n - 1} \subseteq T_pM\) with respect to \(g(p)\). Extend \(X\) o \(\text{Ball}_1(0) \setminus \{0\} = \{a \in T_pM: |a|_g \leq 1\}\). \(\tilde X(r, v) = rX(v)\) on \(B \setminus \{0\}\). Define
  \[
    Y(f(r, v)) = d(\exp_p)_{rv} \tilde X(r, v),
  \]
  a vector field on \(B' \subseteq \exp_p(B \setminus \{0\}) \subseteq M\). To show \(Y \perp \frac{\p}{\p r}\) at each point in \(B' \setminus \{p\}\), note that
  \[
    \frac{\p}{\p r} = \dot \gamma_p(t, a) \frac{1}{|a|_{g(p)}}
  \]
  so \(\dot \gamma(t, a)\) defines a vector field on \(B' \setminus \{p\}\) for all \(|a|_{g(p)} = 1\) and \(0 < t < \varepsilon\). Take limit as \(r \to 0\) to obtain \(g(\frac{\partial  }{\partial r}, \frac{\partial  }{\partial r}) = 1\).

  Thus to show \(g(Y, \dot \gamma) = 0\),
  \begin{align*}
    D_{\dot \gamma} Y - D_Y \dot \gamma
    &= (df)(D_{\p/\p r} \tilde X - D_{\tilde X} \frac{\partial  }{\partial r}) \\
    &= (df) (\frac{d}{dr} \tilde X) \\
    &= (df) \frac{\tilde X}{r} \\
    &= \frac{Y}{r}
  \end{align*}
  by linearity of \(df\) at each point. Thus
  \begin{align*}
    \frac{d}{dr} g(Y, \dot \gamma)
    &= g(D_{\dot \gamma} Y, \dot \gamma) + g(Y, \underbrace{D_{\dot \gamma} \dot \gamma}_{= 0}) \\
    &= g(D_Y \dot \gamma + \frac{Y}{r}, \dot \gamma) \\
    &= \frac{1}{r} g(Y, \dot \gamma)
  \end{align*}
  Let \(G = g(Y, \dot \gamma)\) and we have an ODE
  \[
    \frac{d}{dr} G = \frac{G}{r}.
  \]
  So \(G\) is linear in \(r\) and \(\frac{dG}{dr}\) is independent of \(r\). But
  \[
    \lim_{r \to o^+} \frac{dG}{dr} = \lim_{r \to 0^+} g(X, \frac{\partial  }{\partial r}) = 0
  \]
  because \((d \exp)_0\) is an isometry.
\end{proof}

























\printindex
\end{document}

% https://www.dpmms.cam.ac.uk/~agk22/teaching.html